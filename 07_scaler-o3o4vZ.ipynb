{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escalado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# sns.set()\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "s20k = pd.read_pickle(\"data/o3o4vZ/s20K.pkl.bz2\")\n",
    "s2_5k = pd.read_pickle(\"data/o3o4vZ/s5K.pkl.bz2\")\n",
    "s5k = pd.read_pickle(\"data/o3o4vZ/s2_5K.pkl.bz2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removemos los features que no queremos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['b262', 'b263', 'b261', 'b264', 'b278', 'b247', 'b248', 'b277',\n",
       "       'b234'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_drop = [\n",
    "    'Gskew', # has nan in the rlyrae stars\n",
    "    \"scls_h\", \"scls_j\", \"scls_k\"  # no nos sirve\n",
    "] + [s for s in s20k.columns if s.startswith(\"Freq2_\") or s.startswith(\"Freq3_\") ] # only the first period is important\n",
    "to_keep = [c for c in s20k.columns if c not in to_drop]\n",
    "\n",
    "s20k = s20k[to_keep]\n",
    "s5k = s5k[to_keep]\n",
    "s2_5k = s2_5k = s2_5k[to_keep]\n",
    "\n",
    "s20k[\"id\"].apply(lambda i: \"b\" + str(i)[1:4]).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removemos filas que tengan un nan en `period_fit` pero antes nos fijamos que ninguna sea una RR-Lyrae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ECL-C' '' 'ECL-NC']\n",
      "['ECL-C' '' 'ECL-NC']\n",
      "['ECL-C' '' 'ECL-NC']\n"
     ]
    }
   ],
   "source": [
    "print s20k[s20k.Period_fit.isnull()].vs_type.unique()\n",
    "print s5k[s5k.Period_fit.isnull()].vs_type.unique()\n",
    "print s2_5k[s2_5k.Period_fit.isnull()].vs_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s20k = s20k.dropna()\n",
    "s5k = s5k.dropna()\n",
    "s2_5k = s2_5k.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['b262', 'b263', 'b261', 'b264', 'b278', 'b247', 'b248', 'b277',\n",
       "       'b234'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s20k[\"id\"].apply(lambda i: \"b\" + str(i)[1:4]).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos que columnas tienen un valor infinito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Period_fit\n"
     ]
    }
   ],
   "source": [
    "for x in s20k.columns:\n",
    "    if s20k[x].dtype == object:\n",
    "        continue\n",
    "    if np.isinf(s20k[x].values).sum() + np.isinf(s5k[x].values).sum() + np.isinf(s2_5k[x].values).sum():\n",
    "        print x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como period_fit es un feature que me interesa, verificamos que cantidad de filas son las afectadas\n",
    "y si hay alguna con RRLyraes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 64)\n",
      "(12, 64)\n",
      "(43, 64)\n",
      "['ECL-NC' '']\n",
      "['ECL-NC' '']\n",
      "['ECL-NC' '']\n"
     ]
    }
   ],
   "source": [
    "print s2_5k[np.isinf(s2_5k.Period_fit.values)].shape\n",
    "print s5k[np.isinf(s5k.Period_fit.values)].shape\n",
    "print s20k[np.isinf(s20k.Period_fit.values)].shape\n",
    "\n",
    "print s2_5k[np.isinf(s2_5k.Period_fit.values)].vs_type.unique()\n",
    "print s5k[np.isinf(s5k.Period_fit.values)].vs_type.unique()\n",
    "print s20k[np.isinf(s20k.Period_fit.values)].vs_type.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Son pocas filas y no hay rrlyraes... las borramos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "s20k = s20k[~np.isinf(s20k.Period_fit.values)]\n",
    "s5k = s5k[~np.isinf(s5k.Period_fit.values)]\n",
    "s2_5k = s2_5k[~np.isinf(s2_5k.Period_fit.values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ahora almacenamos tod esto limpio para futuros usos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "s20k.to_pickle(\"data/o3o4vZ/nonull/s20k.pkl.bz2\", compression=\"bz2\")\n",
    "s5k.to_pickle(\"data/o3o4vZ/nonull/s5k.pkl.bz2\", compression=\"bz2\")\n",
    "s2_5k.to_pickle(\"data/o3o4vZ/nonull/s2_5k.pkl.bz2\", compression=\"bz2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahora normalizamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_features = [\"id\", \"vs_catalog\", \"vs_type\", \"ra_k\", \"dec_k\", ] \n",
    "X_columns = [c for c in s20k.columns if c not in no_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "splited = {idx+1: list(s) for idx, s in enumerate(np.array_split(X_columns, 19))}\n",
    "maxs = max(map(len, splited.values()))\n",
    "for v in splited.values():\n",
    "    while len(v) < maxs:\n",
    "        v.append(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feats = pd.DataFrame(splited).T\n",
    "# feats\n",
    "# print feats.to_latex(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/proyectos/paper_b278/local/lib/python2.7/site-packages/numpy/core/_methods.py:116: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n"
     ]
    }
   ],
   "source": [
    "scaler_20k = StandardScaler()\n",
    "norm_s20k = s20k.copy()\n",
    "norm_s20k[X_columns] = scaler_20k.fit_transform(s20k[X_columns])\n",
    "pickle.dump(scaler_20k, open(\"data/o3o4vZ/scalers/scaler_20k.pkl\", \"wb\"))\n",
    "norm_s20k.to_pickle(\"data/o3o4vZ/scaled/s20k.pkl.bz2\", compression=\"bz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_5k = StandardScaler()\n",
    "norm_s5k = s5k.copy()\n",
    "norm_s5k[X_columns] = scaler_5k.fit_transform(s5k[X_columns])\n",
    "pickle.dump(scaler_5k, open(\"data/o3o4vZ/scalers/scaler_5k.pkl\", \"wb\"))\n",
    "norm_s5k.to_pickle(\"data/o3o4vZ/scaled/s5k.pkl.bz2\", compression=\"bz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_2_5k = StandardScaler()\n",
    "norm_s2_5k = s2_5k.copy()\n",
    "norm_s2_5k[X_columns] = scaler_2_5k.fit_transform(s2_5k[X_columns])\n",
    "pickle.dump(scaler_2_5k, open(\"data/o3o4vZ/scalers/scaler_2_5k.pkl\", \"wb\"))\n",
    "norm_s2_5k.to_pickle(\"data/o3o4vZ/scaled/s2_5k.pkl.bz2\", compression=\"bz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = {k: {\"Tile\": k} for k in \"b261 b262 b263 b264 b278 b277 b247 b248 b234\".split()}\n",
    "    \n",
    "for nombre, s in zip([\"Chica\", \"Mediana\", \"Grande\"] , [s2_5k,s5k,s20k]):\n",
    "    s = s.copy()\n",
    "    s[\"tile\"] = s[\"id\"].apply(lambda i: \"b\" + str(i)[1:4])\n",
    "    grouped = s.groupby(\"tile\")\n",
    "    data = {k: grouped.get_group(k).copy() for k in grouped.groups.keys()}\n",
    "    for tile, df in data.items():\n",
    "        row = rows[tile]\n",
    "        row.update({\n",
    "            nombre : len(df[df.vs_type.str.contains(\"\")]),\n",
    "            \"RR-Lyrae\": len(df[df.vs_type.str.startswith(\"RRLyr\")]),\n",
    "        })\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = s20k.copy()\n",
    "s[\"tile\"] = s[\"id\"].apply(lambda i: \"b\" + str(i)[1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['b262', 'b263', 'b261', 'b264', 'b278', 'b247', 'b248', 'b277',\n",
       "       'b234'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.tile.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Mediana': 4070, 'Chica': 6568, 'Grande': 21557, 'Tile': 'b247', 'RR-Lyrae': 192}\n",
      "{'Mediana': 4521, 'Chica': 7017, 'Grande': 21997, 'Tile': 'b248', 'RR-Lyrae': 222}\n",
      "{'Mediana': 5465, 'Chica': 7957, 'Grande': 22929, 'Tile': 'b262', 'RR-Lyrae': 318}\n",
      "{'Mediana': 5572, 'Chica': 8071, 'Grande': 23067, 'Tile': 'b263', 'RR-Lyrae': 319}\n",
      "{'Mediana': 5407, 'Chica': 7902, 'Grande': 22883, 'Tile': 'b261', 'RR-Lyrae': 253}\n",
      "{'Mediana': 5699, 'Chica': 8198, 'Grande': 23196, 'Tile': 'b264', 'RR-Lyrae': 312}\n",
      "{'Mediana': 3281, 'Chica': 5779, 'Grande': 20777, 'Tile': 'b234', 'RR-Lyrae': 126}\n",
      "{'Mediana': 6463, 'Chica': 8964, 'Grande': 23896, 'Tile': 'b277', 'RR-Lyrae': 434}\n",
      "{'Mediana': 7058, 'Chica': 9552, 'Grande': 24509, 'Tile': 'b278', 'RR-Lyrae': 441}\n"
     ]
    }
   ],
   "source": [
    "for r in rows.values():\n",
    "    print r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      " Tile &  Chica &  Mediana &  Grande &  RR-Lyrae \\\\\n",
      "\\midrule\n",
      " b234 &   5779 &     3281 &   20777 &       126 \\\\\n",
      " b247 &   6568 &     4070 &   21557 &       192 \\\\\n",
      " b248 &   7017 &     4521 &   21997 &       222 \\\\\n",
      " b261 &   7902 &     5407 &   22883 &       253 \\\\\n",
      " b262 &   7957 &     5465 &   22929 &       318 \\\\\n",
      " b263 &   8071 &     5572 &   23067 &       319 \\\\\n",
      " b264 &   8198 &     5699 &   23196 &       312 \\\\\n",
      " b277 &   8964 &     6463 &   23896 &       434 \\\\\n",
      " b278 &   9552 &     7058 &   24509 &       441 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print pd.DataFrame(\n",
    "    [v for v in rows.values()]\n",
    ")[\n",
    "    \"Tile Chica Mediana Grande RR-Lyrae\".split()\n",
    "].sort_values(\"Tile\").to_latex(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
