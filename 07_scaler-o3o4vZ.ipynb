{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escalado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# sns.set()\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_5k = pd.read_pickle(\"data/o3o4vZ/s2_5K.pkl.bz2\")\n",
    "s5k = pd.read_pickle(\"data/o3o4vZ/s5K.pkl.bz2\")\n",
    "s20k = pd.read_pickle(\"data/o3o4vZ/s20K.pkl.bz2\")\n",
    "sALL = pd.read_pickle(\"data/o3o4vZ/sampleALL_b261_b278.pkl.bz2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removemos todo lo que no sea RRLyrae o desconocido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_only_rr_unk(df):\n",
    "    flt = (df.vs_type == \"\") | df.vs_type.str.startswith('RRLyr-')\n",
    "    return df[flt]\n",
    "\n",
    "s2_5k = filter_only_rr_unk(s2_5k)\n",
    "s5k = filter_only_rr_unk(s5k)\n",
    "s20k = filter_only_rr_unk(s20k)\n",
    "sALL = filter_only_rr_unk(sALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removemos los features que no queremos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['b262', 'b263', 'b261', 'b264', 'b278', 'b247', 'b248', 'b277',\n",
       "       'b234'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_drop = [\n",
    "    'Gskew', # has nan in the rlyrae stars\n",
    "    \"scls_h\", \"scls_j\", \"scls_k\",  # no nos sirve\n",
    "    \"AndersonDarling\", \"StetsonJ\", \"StetsonK\"\n",
    "] + [s for s in s20k.columns if s.startswith(\"Freq2_\") or s.startswith(\"Freq3_\") ] # only the first period is important\n",
    "to_keep = [c for c in s20k.columns if c not in to_drop]\n",
    "\n",
    "s20k = s20k[to_keep]\n",
    "s5k = s5k[to_keep]\n",
    "s2_5k = s2_5k[to_keep]\n",
    "sALL = sALL[to_keep]\n",
    "\n",
    "s20k[\"id\"].apply(lambda i: \"b\" + str(i)[1:4]).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removemos filas que tengan un nan en `period_fit` pero antes nos fijamos que ninguna sea una RR-Lyrae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['']\n",
      "['']\n",
      "['']\n",
      "['']\n"
     ]
    }
   ],
   "source": [
    "print s20k[s20k.Period_fit.isnull()].vs_type.unique()\n",
    "print s5k[s5k.Period_fit.isnull()].vs_type.unique()\n",
    "print s2_5k[s2_5k.Period_fit.isnull()].vs_type.unique()\n",
    "print sALL[sALL.Period_fit.isnull()].vs_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Period_fit'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sALL.columns[sALL.isnull().any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s20k = s20k.dropna()\n",
    "s5k = s5k.dropna()\n",
    "s2_5k = s2_5k.dropna()\n",
    "sALL = sALL.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b262' 'b263' 'b261' 'b264' 'b278' 'b247' 'b248' 'b277' 'b234']\n",
      "['b261' 'b278']\n"
     ]
    }
   ],
   "source": [
    "print s20k[\"id\"].apply(lambda i: \"b\" + str(i)[1:4]).unique()\n",
    "print sALL[\"id\"].apply(lambda i: \"b\" + str(i)[1:4]).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos que columnas tienen un valor infinito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Period_fit\n"
     ]
    }
   ],
   "source": [
    "for x in s20k.columns:\n",
    "    if s20k[x].dtype == object:\n",
    "        continue\n",
    "    if np.isinf(s20k[x].values).sum() + np.isinf(s5k[x].values).sum() + np.isinf(s2_5k[x].values).sum() + np.isinf(sALL[x].values).sum():\n",
    "        print x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como period_fit es un feature que me interesa, verificamos que cantidad de filas son las afectadas\n",
    "y si hay alguna con RRLyraes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 62)\n",
      "(5, 62)\n",
      "(36, 62)\n",
      "(614, 62)\n",
      "['']\n",
      "['']\n",
      "['']\n",
      "['']\n"
     ]
    }
   ],
   "source": [
    "print s2_5k[np.isinf(s2_5k.Period_fit.values)].shape\n",
    "print s5k[np.isinf(s5k.Period_fit.values)].shape\n",
    "print s20k[np.isinf(s20k.Period_fit.values)].shape\n",
    "print sALL[np.isinf(sALL.Period_fit.values)].shape\n",
    "\n",
    "print s2_5k[np.isinf(s2_5k.Period_fit.values)].vs_type.unique()\n",
    "print s5k[np.isinf(s5k.Period_fit.values)].vs_type.unique()\n",
    "print s20k[np.isinf(s20k.Period_fit.values)].vs_type.unique()\n",
    "print sALL[np.isinf(sALL.Period_fit.values)].vs_type.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Son pocas filas y no hay rrlyraes... las borramos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "s20k = s20k[~np.isinf(s20k.Period_fit.values)]\n",
    "s5k = s5k[~np.isinf(s5k.Period_fit.values)]\n",
    "s2_5k = s2_5k[~np.isinf(s2_5k.Period_fit.values)]\n",
    "sALL = sALL[~np.isinf(sALL.Period_fit.values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ahora almacenamos tod esto limpio para futuros usos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "s20k.to_pickle(\"data/o3o4vZ/nonull/s20k.pkl.bz2\", compression=\"bz2\")\n",
    "s5k.to_pickle(\"data/o3o4vZ/nonull/s5k.pkl.bz2\", compression=\"bz2\")\n",
    "s2_5k.to_pickle(\"data/o3o4vZ/nonull/s2_5k.pkl.bz2\", compression=\"bz2\")\n",
    "sALL.to_pickle(\"data/o3o4vZ/nonull/sALL.pkl.bz2\", compression=\"bz2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahora normalizamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_features = [\"id\", \"vs_catalog\", \"vs_type\", \"ra_k\", \"dec_k\", ] \n",
    "X_columns = [c for c in s20k.columns if c not in no_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "splited = {idx+1: list(s) for idx, s in enumerate(np.array_split(X_columns, 19))}\n",
    "maxs = max(map(len, splited.values()))\n",
    "for v in splited.values():\n",
    "    while len(v) < maxs:\n",
    "        v.append(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbcabral/.conda/envs/carpyncho3/lib/python2.7/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/home/jbcabral/.conda/envs/carpyncho3/lib/python2.7/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "scaler_20k = StandardScaler()\n",
    "norm_s20k = s20k.copy()\n",
    "norm_s20k[X_columns] = scaler_20k.fit_transform(s20k[X_columns])\n",
    "pickle.dump(scaler_20k, open(\"data/o3o4vZ/scalers/scaler_20k.pkl\", \"wb\"))\n",
    "norm_s20k.to_pickle(\"data/o3o4vZ/scaled/s20k.pkl.bz2\", compression=\"bz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_5k = StandardScaler()\n",
    "norm_s5k = s5k.copy()\n",
    "norm_s5k[X_columns] = scaler_5k.fit_transform(s5k[X_columns])\n",
    "pickle.dump(scaler_5k, open(\"data/o3o4vZ/scalers/scaler_5k.pkl\", \"wb\"))\n",
    "norm_s5k.to_pickle(\"data/o3o4vZ/scaled/s5k.pkl.bz2\", compression=\"bz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_2_5k = StandardScaler()\n",
    "norm_s2_5k = s2_5k.copy()\n",
    "norm_s2_5k[X_columns] = scaler_2_5k.fit_transform(s2_5k[X_columns])\n",
    "pickle.dump(scaler_2_5k, open(\"data/o3o4vZ/scalers/scaler_2_5k.pkl\", \"wb\"))\n",
    "norm_s2_5k.to_pickle(\"data/o3o4vZ/scaled/s2_5k.pkl.bz2\", compression=\"bz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = {k: {\"Tile\": k} for k in \"b261 b262 b263 b264 b278 b277 b247 b248 b234\".split()}\n",
    "    \n",
    "for nombre, s in zip([\"Chica\", \"Mediana\", \"Grande\"] , [s2_5k,s5k,s20k]):\n",
    "    s = s.copy()\n",
    "    s[\"tile\"] = s[\"id\"].apply(lambda i: \"b\" + str(i)[1:4])\n",
    "    grouped = s.groupby(\"tile\")\n",
    "    data = {k: grouped.get_group(k).copy() for k in grouped.groups.keys()}\n",
    "    for tile, df in data.items():\n",
    "        row = rows[tile]\n",
    "        row.update({\n",
    "            nombre : len(df[df.vs_type.str.contains(\"\")]),\n",
    "            \"RR-Lyrae\": len(df[df.vs_type.str.startswith(\"RRLyr\")]),\n",
    "        })\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = s20k.copy()\n",
    "s[\"tile\"] = s[\"id\"].apply(lambda i: \"b\" + str(i)[1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['b262', 'b263', 'b261', 'b264', 'b278', 'b247', 'b248', 'b277',\n",
       "       'b234'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.tile.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Mediana': 5188, 'Chica': 2690, 'Grande': 20177, 'Tile': 'b247', 'RR-Lyrae': 192}\n",
      "{'Mediana': 5217, 'Chica': 2721, 'Grande': 20197, 'Tile': 'b248', 'RR-Lyrae': 222}\n",
      "{'Mediana': 5307, 'Chica': 2815, 'Grande': 20279, 'Tile': 'b262', 'RR-Lyrae': 318}\n",
      "{'Mediana': 5317, 'Chica': 2818, 'Grande': 20313, 'Tile': 'b263', 'RR-Lyrae': 319}\n",
      "{'Mediana': 5246, 'Chica': 2751, 'Grande': 20227, 'Tile': 'b261', 'RR-Lyrae': 253}\n",
      "{'Mediana': 5310, 'Chica': 2811, 'Grande': 20309, 'Tile': 'b264', 'RR-Lyrae': 312}\n",
      "{'Mediana': 5123, 'Chica': 2625, 'Grande': 20121, 'Tile': 'b234', 'RR-Lyrae': 126}\n",
      "{'Mediana': 5425, 'Chica': 2924, 'Grande': 20357, 'Tile': 'b277', 'RR-Lyrae': 434}\n",
      "{'Mediana': 5424, 'Chica': 2930, 'Grande': 20381, 'Tile': 'b278', 'RR-Lyrae': 441}\n"
     ]
    }
   ],
   "source": [
    "for r in rows.values():\n",
    "    print r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      " Tile &  Chica &  Mediana &  Grande &  RR-Lyrae \\\\\n",
      "\\midrule\n",
      " b234 &   2625 &     5123 &   20121 &       126 \\\\\n",
      " b247 &   2690 &     5188 &   20177 &       192 \\\\\n",
      " b248 &   2721 &     5217 &   20197 &       222 \\\\\n",
      " b261 &   2751 &     5246 &   20227 &       253 \\\\\n",
      " b262 &   2815 &     5307 &   20279 &       318 \\\\\n",
      " b263 &   2818 &     5317 &   20313 &       319 \\\\\n",
      " b264 &   2811 &     5310 &   20309 &       312 \\\\\n",
      " b277 &   2924 &     5425 &   20357 &       434 \\\\\n",
      " b278 &   2930 &     5424 &   20381 &       441 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print pd.DataFrame(\n",
    "    [v for k, v in sorted(rows.items())]\n",
    ")[\n",
    "    \"Tile Chica Mediana Grande RR-Lyrae\".split()\n",
    "].sort_values(\"Tile\").to_latex(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
