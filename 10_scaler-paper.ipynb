{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escalado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# sns.set()\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_5k = pd.concat([\n",
    "    pd.read_pickle(\"data/o3o4vZ/s2_5k.pkl.bz2\"),\n",
    "    pd.read_pickle(\"data/paper/news_s2500.pkl.bz2\")], ignore_index=True)\n",
    "\n",
    "s5k = pd.concat([\n",
    "    pd.read_pickle(\"data/o3o4vZ/s5k.pkl.bz2\"),\n",
    "    pd.read_pickle(\"data/paper/news_s5k.pkl.bz2\")], ignore_index=True)\n",
    "\n",
    "s20k = pd.concat([\n",
    "    pd.read_pickle(\"data/o3o4vZ/s20k.pkl.bz2\"),\n",
    "    pd.read_pickle(\"data/paper/news_s20k.pkl.bz2\")], ignore_index=True)\n",
    "\n",
    "sO2O = pd.read_pickle(\"data/paper/sO2O.pkl.bz2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregamos la columna tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tile(df):\n",
    "    df = df.copy()\n",
    "    df[\"tile\"] = df.id.apply(lambda i: \"b\" + str(i)[1:4])\n",
    "    return df\n",
    "\n",
    "s2_5k = add_tile(s2_5k)\n",
    "s5k = add_tile(s5k)\n",
    "s20k = add_tile(s20k)\n",
    "sO2O = add_tile(sO2O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b206', 'b214', 'b216', 'b220', 'b228', 'b234', 'b247', 'b248', 'b261', 'b262', 'b263', 'b264', 'b277', 'b278', 'b360', 'b396']\n",
      "['b206', 'b214', 'b216', 'b220', 'b228', 'b234', 'b247', 'b248', 'b261', 'b262', 'b263', 'b264', 'b277', 'b278', 'b360', 'b396']\n",
      "['b206', 'b214', 'b216', 'b220', 'b228', 'b234', 'b247', 'b248', 'b261', 'b262', 'b263', 'b264', 'b277', 'b278', 'b360', 'b396']\n",
      "['b206', 'b214', 'b216', 'b220', 'b228', 'b234', 'b247', 'b248', 'b261', 'b262', 'b263', 'b264', 'b277', 'b278', 'b360', 'b396']\n"
     ]
    }
   ],
   "source": [
    "print sorted(s5k.tile.unique())\n",
    "print sorted(s2_5k.tile.unique())\n",
    "print sorted(s20k.tile.unique())\n",
    "print sorted(sO2O.tile.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removemos todo lo que no sea RRLyrae o desconocido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_only_rr_unk(df):\n",
    "    flt = (df.vs_type == \"\") | df.vs_type.str.startswith('RRLyr-')\n",
    "    return df[flt]\n",
    "\n",
    "s2_5k = filter_only_rr_unk(s2_5k)\n",
    "s5k = filter_only_rr_unk(s5k)\n",
    "s20k = filter_only_rr_unk(s20k)\n",
    "sO2O = filter_only_rr_unk(sO2O)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removemos los features que no queremos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removemos filas que tengan un nan en `period_fit` pero antes nos fijamos que ninguna sea una RR-Lyrae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['']\n",
      "['']\n",
      "['']\n",
      "['']\n"
     ]
    }
   ],
   "source": [
    "print s20k[s20k.Period_fit.isnull()].vs_type.unique()\n",
    "print s5k[s5k.Period_fit.isnull()].vs_type.unique()\n",
    "print s2_5k[s2_5k.Period_fit.isnull()].vs_type.unique()\n",
    "print sO2O[sO2O.Period_fit.isnull()].vs_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s20k = s20k.dropna()\n",
    "s5k = s5k.dropna()\n",
    "s2_5k = s2_5k.dropna()\n",
    "sO2O = sO2O.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos que columnas tienen un valor infinito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Period_fit\n"
     ]
    }
   ],
   "source": [
    "for x in s20k.columns:\n",
    "    if s20k[x].dtype == object:\n",
    "        continue\n",
    "    if np.isinf(s20k[x].values).sum() + np.isinf(s5k[x].values).sum() + np.isinf(s2_5k[x].values).sum() + np.isinf(sO2O[x].values).sum():\n",
    "        print x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como period_fit es un feature que me interesa, verificamos que cantidad de filas son las afectadas\n",
    "y si hay alguna con RRLyraes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 85)\n",
      "(10, 85)\n",
      "(51, 85)\n",
      "(2, 85)\n",
      "['']\n",
      "['']\n",
      "['']\n",
      "['']\n"
     ]
    }
   ],
   "source": [
    "print s2_5k[np.isinf(s2_5k.Period_fit.values)].shape\n",
    "print s5k[np.isinf(s5k.Period_fit.values)].shape\n",
    "print s20k[np.isinf(s20k.Period_fit.values)].shape\n",
    "print sO2O[np.isinf(sO2O.Period_fit.values)].shape\n",
    "\n",
    "print s2_5k[np.isinf(s2_5k.Period_fit.values)].vs_type.unique()\n",
    "print s5k[np.isinf(s5k.Period_fit.values)].vs_type.unique()\n",
    "print s20k[np.isinf(s20k.Period_fit.values)].vs_type.unique()\n",
    "print sO2O[np.isinf(sO2O.Period_fit.values)].vs_type.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Son pocas filas y no hay rrlyraes... las borramos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s20k = s20k[~np.isinf(s20k.Period_fit.values)]\n",
    "s5k = s5k[~np.isinf(s5k.Period_fit.values)]\n",
    "s2_5k = s2_5k[~np.isinf(s2_5k.Period_fit.values)]\n",
    "sO2O = sO2O[~np.isinf(sO2O.Period_fit.values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ahora almacenamos tod esto limpio para futuros usos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "s20k.to_pickle(\"data/paper/nonull/s20k.pkl.bz2\", compression=\"bz2\")\n",
    "s5k.to_pickle(\"data/paper/nonull/s5k.pkl.bz2\", compression=\"bz2\")\n",
    "s2_5k.to_pickle(\"data/paper/nonull/s2_5k.pkl.bz2\", compression=\"bz2\")\n",
    "sO2O.to_pickle(\"data/paper/nonull/sO2O.pkl.bz2\", compression=\"bz2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahora normalizamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_features = [\"id\", \"vs_catalog\", \"vs_type\", \"ra_k\", \"dec_k\", \"tile\"] \n",
    "X_columns = [c for c in s20k.columns if c not in no_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_20k = StandardScaler()\n",
    "norm_s20k = s20k.copy()\n",
    "norm_s20k[X_columns] = scaler_20k.fit_transform(s20k[X_columns])\n",
    "pickle.dump(scaler_20k, open(\"data/paper/scalers/scaler_20k.pkl\", \"wb\"))\n",
    "norm_s20k.to_pickle(\"data/paper/scaled/s20k.pkl.bz2\", compression=\"bz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_5k = StandardScaler()\n",
    "norm_s5k = s5k.copy()\n",
    "norm_s5k[X_columns] = scaler_5k.fit_transform(s5k[X_columns])\n",
    "pickle.dump(scaler_5k, open(\"data/paper/scalers/scaler_5k.pkl\", \"wb\"))\n",
    "norm_s5k.to_pickle(\"data/paper/scaled/s5k.pkl.bz2\", compression=\"bz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_2_5k = StandardScaler()\n",
    "norm_s2_5k = s2_5k.copy()\n",
    "norm_s2_5k[X_columns] = scaler_2_5k.fit_transform(s2_5k[X_columns])\n",
    "pickle.dump(scaler_2_5k, open(\"data/paper/scalers/scaler_2_5k.pkl\", \"wb\"))\n",
    "norm_s2_5k.to_pickle(\"data/paper/scaled/s2_5k.pkl.bz2\", compression=\"bz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_sO2O = StandardScaler()\n",
    "norm_sO2O = sO2O.copy()\n",
    "norm_sO2O[X_columns] = scaler_sO2O.fit_transform(sO2O[X_columns])\n",
    "pickle.dump(scaler_sO2O, open(\"data/paper/scalers/scaler_sO2O.pkl\", \"wb\"))\n",
    "norm_sO2O.to_pickle(\"data/paper/scaled/sO2O.pkl.bz2\", compression=\"bz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosos = sorted(norm_s2_5k.tile.unique())\n",
    "rows = {k: {\"Tile\": k} for k in cosos}\n",
    "    \n",
    "for nombre, s in zip([\"UaU\", \"Chica\", \"Mediana\", \"Grande\", ] , [sO2O, s2_5k,s5k,s20k, ]):\n",
    "    s = s.copy()\n",
    "    s[\"tile\"] = s[\"id\"].apply(lambda i: \"b\" + str(i)[1:4])\n",
    "    grouped = s.groupby(\"tile\")\n",
    "    data = {k: grouped.get_group(k).copy() for k in grouped.groups.keys()}\n",
    "    for tile, df in data.items():\n",
    "        row = rows[tile]\n",
    "        row.update({\n",
    "            nombre : len(df[df.vs_type.str.contains(\"\")]),\n",
    "            \"RR-Lyrae\": len(df[df.vs_type.str.startswith(\"RRLyr\")]),\n",
    "        })\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      " Tile &   UaU &  Chica &  Mediana &  Grande &  RR-Lyrae \\\\\n",
      "\\midrule\n",
      " b206 &    94 &   2547 &     5047 &   20045 &        47 \\\\\n",
      " b214 &    68 &   2534 &     5034 &   20031 &        34 \\\\\n",
      " b216 &    86 &   2540 &     5039 &   20033 &        43 \\\\\n",
      " b220 &   130 &   2565 &     5065 &   20065 &        65 \\\\\n",
      " b228 &    56 &   2528 &     5028 &   20023 &        28 \\\\\n",
      " b234 &   252 &   2625 &     5126 &   20124 &       126 \\\\\n",
      " b247 &   384 &   2692 &     5190 &   20182 &       192 \\\\\n",
      " b248 &   442 &   2719 &     5219 &   20197 &       222 \\\\\n",
      " b261 &   506 &   2751 &     5245 &   20224 &       253 \\\\\n",
      " b262 &   635 &   2809 &     5313 &   20267 &       318 \\\\\n",
      " b263 &   638 &   2819 &     5317 &   20310 &       319 \\\\\n",
      " b264 &   624 &   2811 &     5309 &   20300 &       312 \\\\\n",
      " b277 &   867 &   2923 &     5413 &   20371 &       434 \\\\\n",
      " b278 &   879 &   2929 &     5424 &   20363 &       440 \\\\\n",
      " b360 &  1364 &   3181 &     5680 &   20676 &       682 \\\\\n",
      " b396 &    30 &   2512 &     5010 &   20002 &        15 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print pd.DataFrame(\n",
    "    [v for k, v in sorted(rows.items())]\n",
    ")[\n",
    "    \"Tile UaU Chica Mediana Grande RR-Lyrae\".split()\n",
    "].sort_values(\"Tile\").to_latex(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
