{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Analysis Primer For b278 VVV Tile\n",
    "\n",
    "- **author:** JB Cabral (<jbc.develop@gmail.com>)\n",
    "\n",
    "This binary clasification are made over a 20424 samples of the b278 tile, where:\n",
    "\n",
    "- 424 are RRLyrae.\n",
    "- 20000 are not RRLyrae."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "# import seaborn as sns\n",
    "# sns.set()\n",
    "\n",
    "import sklearn\n",
    "from sklearn import feature_selection as fs\n",
    "from sklearn import preprocessing as prp\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import (\n",
    "    KFold, StratifiedKFold, train_test_split)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from IPython import display as d\n",
    "\n",
    "from lime import lime_tabular as lt\n",
    "\n",
    "from joblib import Memory\n",
    "\n",
    "from libs import container\n",
    "\n",
    "pd.options.mode.chained_assignment = None \n",
    "\n",
    "memory = Memory(cachedir=\"cache\", verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading '/home/data/carpyncho/stored/samples/b220_sample.npy'...\n",
      "Loading '/home/data/carpyncho/stored/samples/b262_sample.npy'...\n",
      "Loading '/home/data/carpyncho/stored/samples/b278_sample.npy'...\n",
      "Loading '/home/data/carpyncho/stored/samples/b261_sample.npy'...\n",
      "Loading '/home/data/carpyncho/stored/samples/b264_sample.npy'...\n",
      "Loading '/home/data/carpyncho/stored/samples/b263_sample.npy'...\n",
      "Removing b220...\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/data/carpyncho/stored/samples/\"\n",
    "data = container.read(path)\n",
    "\n",
    "print(\"Removing b220...\")\n",
    "del data[\"b220\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2. Preprocess\n",
    "\n",
    "### 2.1. Discretize the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Classes"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'': 0,\n",
       " 'Cep-1': 1,\n",
       " 'Cep-F': 2,\n",
       " 'LPV-Mira': 3,\n",
       " 'LPV-OSARG': 4,\n",
       " 'LPV-SRV': 5,\n",
       " 'RRLyr-RRab': 6,\n",
       " 'RRLyr-RRc': 7,\n",
       " 'RRLyr-RRd': 8,\n",
       " 'T2Cep-BLHer': 9,\n",
       " 'T2Cep-RVTau': 10,\n",
       " 'T2Cep-WVir': 11}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Simplified Classes"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'': 0, 'Cep': 1, 'LPV': 2, 'RRLyr': 3, 'T2Cep': 4}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = set()\n",
    "for df in data.values():\n",
    "    classes.update(df.ogle3_type)\n",
    "sclasses_names = set(c.split(\"-\", 1)[0] for c in classes)\n",
    "classes = dict(zip(sorted(classes), range(len(classes))))\n",
    "sclasses = dict(zip(sorted(sclasses_names), range(len(sclasses_names))))\n",
    "\n",
    "for df in data.values():\n",
    "    df[\"cls\"] = df.ogle3_type.apply(classes.get)\n",
    "    df[\"scls\"] = df.ogle3_type.apply(lambda v: sclasses.get(v.split(\"-\", 1)[0]))\n",
    "    \n",
    "d.display(d.Markdown(\"### Classes\"))\n",
    "d.display(classes)\n",
    "\n",
    "d.display(d.Markdown(\"### Simplified Classes\"))\n",
    "d.display(sclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'id', u'ogle3_type', u'cnt', u'AMP', u'Amplitude', u'AndersonDarling',\n",
       "       u'Autocor_length', u'Beyond1Std', u'CAR_mean', u'CAR_sigma', u'CAR_tau',\n",
       "       u'Con', u'Eta_e', u'FluxPercentileRatioMid20',\n",
       "       u'FluxPercentileRatioMid35', u'FluxPercentileRatioMid50',\n",
       "       u'FluxPercentileRatioMid65', u'FluxPercentileRatioMid80',\n",
       "       u'Freq1_harmonics_amplitude_0', u'Freq1_harmonics_amplitude_1',\n",
       "       u'Freq1_harmonics_amplitude_2', u'Freq1_harmonics_amplitude_3',\n",
       "       u'Freq1_harmonics_rel_phase_0', u'Freq1_harmonics_rel_phase_1',\n",
       "       u'Freq1_harmonics_rel_phase_2', u'Freq1_harmonics_rel_phase_3',\n",
       "       u'Freq2_harmonics_amplitude_0', u'Freq2_harmonics_amplitude_1',\n",
       "       u'Freq2_harmonics_amplitude_2', u'Freq2_harmonics_amplitude_3',\n",
       "       u'Freq2_harmonics_rel_phase_0', u'Freq2_harmonics_rel_phase_1',\n",
       "       u'Freq2_harmonics_rel_phase_2', u'Freq2_harmonics_rel_phase_3',\n",
       "       u'Freq3_harmonics_amplitude_0', u'Freq3_harmonics_amplitude_1',\n",
       "       u'Freq3_harmonics_amplitude_2', u'Freq3_harmonics_amplitude_3',\n",
       "       u'Freq3_harmonics_rel_phase_0', u'Freq3_harmonics_rel_phase_1',\n",
       "       u'Freq3_harmonics_rel_phase_2', u'Freq3_harmonics_rel_phase_3',\n",
       "       u'Gskew', u'LinearTrend', u'MaxSlope', u'Mean', u'Meanvariance',\n",
       "       u'MedianAbsDev', u'MedianBRP', u'PairSlopeTrend', u'PercentAmplitude',\n",
       "       u'PercentDifferenceFluxPercentile', u'PeriodLS', u'Period_fit',\n",
       "       u'Psi_CS', u'Psi_eta', u'Q31', u'Rcs', u'Skew', u'SmallKurtosis',\n",
       "       u'Std', u'StetsonK', u'cls', u'scls'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.b278\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Removes all low-variance and \"bad\" features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Raw Features:', 60)\n",
      "('Total features:', 0)\n"
     ]
    }
   ],
   "source": [
    "df = data.b278\n",
    "X_columns = df.columns[~df.columns.isin([\"id\", \"cls\", \"scls\", \"ogle3_type\"])]\n",
    "print(\"Raw Features:\", X_columns.size)\n",
    "\n",
    "# remove signatures\n",
    "X_columns = X_columns[X_columns.str.startswith(\"Signature_\")]\n",
    "X_columns\n",
    "\n",
    "print(\"Total features:\", X_columns.size)\n",
    "\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol></ol>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d.display(d.HTML(\n",
    "    \"<ol>\" +\n",
    "    \"\".join(\"<li>{}</li>\".format(c) for c in X_columns) +\n",
    "    \"</ol>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function fit the classifier with kfolds (`default=10`) print a and retrieve:\n",
    "\n",
    "- **fpr:** False positive rates\n",
    "- **tpr:** True positive rates\n",
    "- **thresh:** Decreasing thresholds on the decision function used to compute fpr and tpr\n",
    "- **roc_auc:** Area under curve of ROC Curve.\n",
    "- **y_test:** Array of all classes of testing samples.\n",
    "- **predictions:** The prediction clases for the testing samples.\n",
    "- **probabilities:** Predicted classes probabilities for tests.\n",
    "- **confussion_matrix:** Confusion matrix to evaluate the accuracy of a classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def experiment(clf, data, train_name, test_name, pcls):\n",
    "    \n",
    "    original_clf = clf\n",
    "    clf = sklearn.clone(original_clf)\n",
    "    \n",
    "    train_df, test_df = data[train_name], data[test_name]\n",
    "    \n",
    "    cfilter = [sclasses[pcls], sclasses[\"\"]]\n",
    "    \n",
    "    train_df = train_df[train_df.scls.isin(cfilter)]\n",
    "    test_df = test_df[test_df.scls.isin(cfilter)]\n",
    "    \n",
    "    x_train = prp.StandardScaler().fit_transform(\n",
    "        train_df[X_columns].values)\n",
    "    y_train = train_df[\"scls\"]\n",
    "\n",
    "    x_test = prp.StandardScaler().fit_transform(\n",
    "        test_df[X_columns].values)\n",
    "    y_testing = test_df[\"scls\"]\n",
    "    \n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "    predictions = clf.predict(x_test)\n",
    "    probabilities = clf.predict_proba(x_test)\n",
    "    \n",
    "    fpr, tpr, thresholds = metrics.roc_curve(\n",
    "        y_testing, 1.-probabilities[:,0], pos_label=cfilter[0])\n",
    "    prec_rec_curve = metrics.precision_recall_curve(\n",
    "        y_testing, 1.- probabilities[:,0], pos_label=cfilter[0])\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    return container.Container({\n",
    "            'test_name': test_name,\n",
    "            'train_name': train_name,\n",
    "            'fpr': fpr, \n",
    "            'tpr': tpr, \n",
    "            'thresh': thresholds, \n",
    "            'roc_auc': roc_auc, \n",
    "            'prec_rec_curve': prec_rec_curve,\n",
    "            'y_test': y_testing, \n",
    "            'predictions': predictions,\n",
    "            'probabilities': probabilities, \n",
    "            'confusion_matrix': metrics.confusion_matrix(y_testing, predictions)})\n",
    "\n",
    "\n",
    "def experiments(clf, data, train_name, pcls, verbose=True):\n",
    "    results = []\n",
    "    for test_name in data.keys():\n",
    "        if test_name != train_name:\n",
    "            rst = experiment(clf, data, train_name, test_name, pcls)\n",
    "            results.append(rst)\n",
    "            if verbose:\n",
    "                print \"{} (TRAIN) Vs. {} (TEST)\".format(rst.train_name, rst.test_name)\n",
    "                print metrics.classification_report(rst.y_test, rst.predictions)\n",
    "                print \"-\" * 80\n",
    "    return tuple(results)\n",
    "\n",
    "\n",
    "def roc(results):\n",
    "    cmap = cm.get_cmap(\"plasma\")\n",
    "    colors = iter(cmap(np.linspace(0, 1, len(results))))\n",
    "\n",
    "    for res  in results:\n",
    "        cname = \"Vs.{}\".format(res.test_name)\n",
    "        color = next(colors)\n",
    "        label = '%s (area = %0.2f)' % (cname, res[\"roc_auc\"])\n",
    "        plt.plot(res[\"fpr\"], res[\"tpr\"], color=color, label=label)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n",
    "def resume(label, results, rfunc):\n",
    "    slice = np.min([r.fpr.size for r in results])\n",
    "    mfpr = rfunc(np.vstack([r.fpr[:slice] for r in results]), axis=0)\n",
    "    mtpr = rfunc(np.vstack([r.tpr[:slice] for r in results]), axis=0)\n",
    "    roc_auc = rfunc([r.roc_auc for r in results])\n",
    "    return container.Container(test_name=label, fpr=mfpr, tpr=mtpr, roc_auc=roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. SVM - Linear\n",
    "\n",
    "Execute a **SVM** with a **linear kernel**. All the default parameters are documented here: http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 feature(s) (shape=(20424, 0)) while a minimum of 1 is required by StandardScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-637f14b14630>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msvc_linear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"b278\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"RRLyr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mroc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvc_linear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-03ad49618ee6>\u001b[0m in \u001b[0;36mexperiments\u001b[0;34m(clf, data, train_name, pcls, verbose)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtest_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtest_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtrain_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mrst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jbcabral/projects/paper_b278/local/lib/python2.7/site-packages/joblib/memory.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jbcabral/projects/paper_b278/local/lib/python2.7/site-packages/joblib/memory.pyc\u001b[0m in \u001b[0;36m_cached_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    508\u001b[0m                           \u001b[0;34m'directory %s'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m                         % (name, argument_hash, output_dir))\n\u001b[0;32m--> 510\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmmap_mode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m                 \u001b[0;31m# Memmap the output at the first call to be consistent with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jbcabral/projects/paper_b278/local/lib/python2.7/site-packages/joblib/memory.pyc\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persist_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-03ad49618ee6>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(clf, data, train_name, test_name, pcls)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     x_train = prp.StandardScaler().fit_transform(\n\u001b[0;32m---> 15\u001b[0;31m         train_df[X_columns].values)\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"scls\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jbcabral/projects/paper_b278/local/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jbcabral/projects/paper_b278/local/lib/python2.7/site-packages/sklearn/preprocessing/data.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jbcabral/projects/paper_b278/local/lib/python2.7/site-packages/sklearn/preprocessing/data.pyc\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    581\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n\u001b[1;32m    582\u001b[0m                         \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m                         estimator=self, dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jbcabral/projects/paper_b278/local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    422\u001b[0m                              \u001b[0;34m\" a minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                              % (n_features, shape_repr, ensure_min_features,\n\u001b[0;32m--> 424\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwarn_on_dtype\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype_orig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdtype_orig\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 feature(s) (shape=(20424, 0)) while a minimum of 1 is required by StandardScaler."
     ]
    }
   ],
   "source": [
    "svc_linear = experiments(svm.SVC(kernel='linear', probability=True), data, \"b278\", \"RRLyr\")\n",
    "roc(svc_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 SVM - Polynomic\n",
    "\n",
    "Execute a **SVM** with a **polynomic kernel**. All the default parameters are documented here: http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time svc_poly = experiments(svm.SVC(kernel='poly', probability=True), data, \"b278\", \"RRLyr\")\n",
    "roc(svc_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Random Forest\n",
    "\n",
    "Execute a **Random Forest** with **500 c45** trees. All the default parameters are documented here: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%time rf = experiments(RandomForestClassifier(n_estimators=500, criterion=\"entropy\"), data, \"b278\", \"RRLyr\")\n",
    "roc(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. KNN\n",
    "\n",
    "KNN with **3** neightbors ad weights determined by the **distance**. Docs: http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time knn = experiments(KNeighborsClassifier(n_neighbors=3, weights='distance'), data, \"b278\", \"RRLyr\")\n",
    "roc(knn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
