{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All vs All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# sns.set()\n",
    "\n",
    "import joblib\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from libs.container import Container\n",
    "from libs.display import d\n",
    "from libs.experiment import KFoldExperiment, WithAnotherExperiment, roc, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_pickle(\"data/o3o4vZ/scaled/s2_5k.pkl.bz2\")\n",
    "sample[\"tile\"] = sample[\"id\"].apply(lambda i: \"b\" + str(i)[1:4])\n",
    "sample[\"cls\"] = sample.vs_type.apply(lambda x: 0 if x == \"\" else 1)\n",
    "\n",
    "no_features = [\"id\", \"vs_catalog\", \"vs_type\", \"ra_k\", \"dec_k\", \"tile\", \"cls\"] \n",
    "X_columns = [c for c in sample.columns if c not in no_features]\n",
    "\n",
    "grouped = sample.groupby(\"tile\")\n",
    "data_small = Container({k: grouped.get_group(k).copy() for k in grouped.groups.keys()})\n",
    "\n",
    "del grouped, sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_pickle(\"data/o3o4vZ/scaled/s5k.pkl.bz2\")\n",
    "sample[\"tile\"] = sample[\"id\"].apply(lambda i: \"b\" + str(i)[1:4])\n",
    "sample[\"cls\"] = sample.vs_type.apply(lambda x: 0 if x == \"\" else 1)\n",
    "\n",
    "grouped = sample.groupby(\"tile\")\n",
    "data_mid = Container({k: grouped.get_group(k).copy() for k in grouped.groups.keys()})\n",
    "\n",
    "del grouped, sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_pickle(\"data/o3o4vZ/scaled/s20k.pkl.bz2\")\n",
    "sample[\"tile\"] = sample[\"id\"].apply(lambda i: \"b\" + str(i)[1:4])\n",
    "sample[\"cls\"] = sample.vs_type.apply(lambda x: 0 if x == \"\" else 1)\n",
    "\n",
    "grouped = sample.groupby(\"tile\")\n",
    "data_big = Container({k: grouped.get_group(k).copy() for k in grouped.groups.keys()})\n",
    "\n",
    "del grouped, sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "cpu = joblib.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = {0:0, 1:1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "1. Amplitude\n",
       "2. AmplitudeH\n",
       "3. AmplitudeJ\n",
       "4. AmplitudeJH\n",
       "5. AmplitudeJK\n",
       "6. Autocor_length\n",
       "7. Beyond1Std\n",
       "8. CAR_mean\n",
       "9. CAR_sigma\n",
       "10. CAR_tau\n",
       "11. Con\n",
       "12. Eta_e\n",
       "13. FluxPercentileRatioMid20\n",
       "14. FluxPercentileRatioMid35\n",
       "15. FluxPercentileRatioMid50\n",
       "16. FluxPercentileRatioMid65\n",
       "17. FluxPercentileRatioMid80\n",
       "18. Freq1_harmonics_amplitude_0\n",
       "19. Freq1_harmonics_amplitude_1\n",
       "20. Freq1_harmonics_amplitude_2\n",
       "21. Freq1_harmonics_amplitude_3\n",
       "22. Freq1_harmonics_rel_phase_0\n",
       "23. Freq1_harmonics_rel_phase_1\n",
       "24. Freq1_harmonics_rel_phase_2\n",
       "25. Freq1_harmonics_rel_phase_3\n",
       "26. LinearTrend\n",
       "27. MaxSlope\n",
       "28. Mean\n",
       "29. Meanvariance\n",
       "30. MedianAbsDev\n",
       "31. MedianBRP\n",
       "32. PairSlopeTrend\n",
       "33. PercentAmplitude\n",
       "34. PercentDifferenceFluxPercentile\n",
       "35. PeriodLS\n",
       "36. Period_fit\n",
       "37. Psi_CS\n",
       "38. Psi_eta\n",
       "39. Q31\n",
       "40. Rcs\n",
       "41. Skew\n",
       "42. SmallKurtosis\n",
       "43. Std\n",
       "44. c89_c3\n",
       "45. c89_hk_color\n",
       "46. c89_jh_color\n",
       "47. c89_jk_color\n",
       "48. c89_m2\n",
       "49. c89_m4\n",
       "50. cnt\n",
       "51. n09_c3\n",
       "52. n09_hk_color\n",
       "53. n09_jh_color\n",
       "54. n09_jk_color\n",
       "55. n09_m2\n",
       "56. n09_m4\n",
       "57. ppmb"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d(X_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(kf, vss):\n",
    "    \n",
    "    kfold_prec = metrics.precision_score(kf.y_test, kf.predictions)\n",
    "    kfold_recall = metrics.recall_score(kf.y_test, kf.predictions)\n",
    "    \n",
    "    m = Container(\n",
    "        kfold=(kfold_prec, kfold_recall), vss=Container())\n",
    "    \n",
    "    for vs in vss:\n",
    "        prec = (\n",
    "            metrics.precision_score(vs.y_test, vs.predictions))\n",
    "        recall = (\n",
    "            metrics.recall_score(vs.y_test, vs.predictions))\n",
    "        m.vss[vs.test_name] = (prec, recall)\n",
    "    \n",
    "    return m\n",
    "\n",
    "\n",
    "def run(train, data):\n",
    "    print \">>>> Kfolding {} <<<<\".format(train)\n",
    "    kf = KFoldExperiment(\n",
    "        clf=RandomForestClassifier(n_estimators=500, criterion=\"entropy\", n_jobs=cpu), clsnum=cls, \n",
    "        data=data, pcls=1, ncls=0, X_columns=X_columns, y_column=\"cls\", verbose=False)\n",
    "    kf = kf(train, nfolds=10)\n",
    "    \n",
    "    print \">>>> Vs {}<<<<\".format(train)\n",
    "    vs = WithAnotherExperiment(\n",
    "        clf=RandomForestClassifier(n_estimators=500, criterion=\"entropy\"), verbose=False, \n",
    "        clsnum=cls, data=data, pcls=1, ncls=0, X_columns=X_columns, y_column=\"cls\")\n",
    "    vs = vs(train)\n",
    "    \n",
    "    return train, get_metrics(kf, vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "cpu = joblib.cpu_count()\n",
    "print cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Kfolding b234 <<<<\n",
      ">>>> Kfolding b247 <<<<\n",
      ">>>> Kfolding b248 <<<<\n",
      ">>>> Kfolding b261 <<<<\n",
      ">>>> Kfolding b262 <<<<\n",
      ">>>> Kfolding b263 <<<<\n",
      ">>>> Kfolding b264 <<<<\n",
      ">>>> Kfolding b277 <<<<\n",
      ">>>> Kfolding b278 <<<<\n",
      ">>>> Vs b247<<<<\n",
      ">>>> Vs b234<<<<\n",
      ">>>> Vs b261<<<<\n",
      ">>>> Vs b248<<<<\n",
      ">>>> Vs b264<<<<\n",
      ">>>> Vs b262<<<<\n",
      ">>>> Vs b278<<<<\n",
      ">>>> Vs b263<<<<\n",
      ">>>> Vs b277<<<<\n"
     ]
    }
   ],
   "source": [
    "with joblib.Parallel(n_jobs=cpu) as jobs:\n",
    "    result = jobs(\n",
    "        joblib.delayed(run)(k, data_small)\n",
    "        for k in sorted(data_small.keys()))\n",
    "results[\"small\"] = dict(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Kfolding b234 <<<<\n",
      ">>>> Kfolding b247 <<<<\n",
      ">>>> Kfolding b248 <<<<\n",
      ">>>> Kfolding b261 <<<<\n",
      ">>>> Kfolding b262 <<<<\n",
      ">>>> Kfolding b263 <<<<\n",
      ">>>> Kfolding b264 <<<<\n",
      ">>>> Kfolding b277 <<<<\n",
      ">>>> Kfolding b278 <<<<\n",
      ">>>> Vs b247<<<<\n",
      ">>>> Vs b234<<<<\n",
      ">>>> Vs b248<<<<\n",
      ">>>> Vs b261<<<<\n",
      ">>>> Vs b263<<<<\n",
      ">>>> Vs b262<<<<\n",
      ">>>> Vs b277<<<<\n",
      ">>>> Vs b264<<<<\n",
      ">>>> Vs b278<<<<\n"
     ]
    }
   ],
   "source": [
    "with joblib.Parallel(n_jobs=cpu) as jobs:\n",
    "    result = jobs(\n",
    "        joblib.delayed(run)(k, data_mid)\n",
    "        for k in sorted(data_mid.keys()))\n",
    "results[\"mid\"] = dict(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Kfolding b234 <<<<\n",
      ">>>> Kfolding b247 <<<<\n",
      ">>>> Kfolding b248 <<<<\n",
      ">>>> Kfolding b261 <<<<\n",
      ">>>> Kfolding b262 <<<<\n",
      ">>>> Kfolding b263 <<<<\n",
      ">>>> Kfolding b264 <<<<\n",
      ">>>> Kfolding b277 <<<<\n",
      ">>>> Kfolding b278 <<<<\n",
      ">>>> Vs b234<<<<\n",
      ">>>> Vs b247<<<<\n",
      ">>>> Vs b263<<<<\n",
      ">>>> Vs b261<<<<\n",
      ">>>> Vs b262<<<<\n",
      ">>>> Vs b248<<<<\n",
      ">>>> Vs b264<<<<\n",
      ">>>> Vs b278<<<<\n",
      ">>>> Vs b277<<<<\n"
     ]
    }
   ],
   "source": [
    "with joblib.Parallel(n_jobs=cpu) as jobs:\n",
    "    result = jobs(\n",
    "        joblib.delayed(run)(k, data_big)\n",
    "        for k in sorted(data_big.keys()))\n",
    "results[\"big\"] = dict(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"data/o3o4vZ/all_vs_all_vs/results.npy\", [results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "03_sample2.5k.ipynb",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
