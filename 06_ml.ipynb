{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AMP Feature Analysis For b278 VVV Tile\n",
    "\n",
    "- **author:** JB Cabral (<jbc.develop@gmail.com>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from sklearn import feature_selection as fs\n",
    "from sklearn import preprocessing as prp\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import neighbors\n",
    "\n",
    "from libs import fourier_help\n",
    "\n",
    "pd.options.mode.chained_assignment = None \n",
    "\n",
    "TWO_LABELS = {-1: -1, 1: 1, 2: 1, 3: 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: 72\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/amp.csv\")\n",
    "print \"features:\", len(df.columns) - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2. Removes all low-variance and \"bad\" features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total features: 62\n"
     ]
    }
   ],
   "source": [
    "# columns with nan and null\n",
    "df = df.loc[:, ~df.isnull().any()]\n",
    "\n",
    "X_columns = df.columns[~df.columns.isin([\"vvv_id\", \"cls\", \"scls\"])]\n",
    "y = df[\"scls\"].values\n",
    "\n",
    "# low variance\n",
    "vt = fs.VarianceThreshold()\n",
    "vt.fit(df[X_columns].values, y)\n",
    "\n",
    "X_columns = X_columns[vt.get_support()]\n",
    "X_scaled = prp.StandardScaler().fit_transform(df[X_columns].values)\n",
    "\n",
    "print \"total features:\", len(X_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def experiment(clf, x, y, nfolds=10):\n",
    "    skf = StratifiedKFold(n_splits=nfolds)\n",
    "    probabilities = np.array([])\n",
    "    predictions = np.array([])\n",
    "    y_testing = np.array([])\n",
    "    \n",
    "    for train, test in skf.split(x, y):\n",
    "        \n",
    "        x_train = x[train]\n",
    "        y_train = y[train]\n",
    "        clf.fit(x_train, y_train)\n",
    "\n",
    "        x_test = x[test]\n",
    "        y_test = y[test]\n",
    "        pr = clf.predict(x_test)\n",
    "        probs = clf.predict_proba(x_test)[:, 0]\n",
    "\n",
    "        probabilities = np.hstack([probabilities, probs])\n",
    "        predictions = np.hstack([predictions, pr])\n",
    "        y_testing = np.hstack([y_testing, y_test])\n",
    "\n",
    "    print metrics.classification_report(y_testing, predictions)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_testing, 1. - probabilities)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    return {'fpr': fpr, \n",
    "            'tpr': tpr, \n",
    "            'thresh': thresholds, \n",
    "            'roc_auc': roc_auc, \n",
    "            'y_test': y_testing, \n",
    "            'predictions': predictions,\n",
    "            'probabilities': probabilities, \n",
    "            'confusion_matrix': metrics.confusion_matrix(y_testing, predictions),\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. SVM - Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.99      1.00      0.99     20000\n",
      "        1.0       0.92      0.49      0.64       424\n",
      "\n",
      "avg / total       0.99      0.99      0.99     20424\n",
      "\n",
      "CPU times: user 4min 26s, sys: 2.45 s, total: 4min 28s\n",
      "Wall time: 4min 30s\n"
     ]
    }
   ],
   "source": [
    "%time svc_linear = experiment(svm.SVC(kernel='linear', probability=True), X_scaled, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 SVM - Polynomic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.99      1.00      0.99     20000\n",
      "        1.0       0.89      0.42      0.57       424\n",
      "\n",
      "avg / total       0.99      0.99      0.98     20424\n",
      "\n",
      "CPU times: user 2min 39s, sys: 1.61 s, total: 2min 41s\n",
      "Wall time: 2min 41s\n"
     ]
    }
   ],
   "source": [
    "%time svc_poly = experiment(svm.SVC(kernel='poly', probability=True), X_scaled, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.99      1.00      1.00     20000\n",
      "        1.0       0.97      0.54      0.70       424\n",
      "\n",
      "avg / total       0.99      0.99      0.99     20424\n",
      "\n",
      "CPU times: user 8min 45s, sys: 229 ms, total: 8min 45s\n",
      "Wall time: 8min 45s\n"
     ]
    }
   ],
   "source": [
    "%time rf = experiment(RandomForestClassifier(n_estimators=500, criterion=\"entropy\"), X_scaled, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       -1.0       0.99      1.00      0.99     20000\n",
      "        1.0       0.83      0.45      0.58       424\n",
      "\n",
      "avg / total       0.99      0.99      0.98     20424\n",
      "\n",
      "CPU times: user 2min 31s, sys: 48 ms, total: 2min 31s\n",
      "Wall time: 2min 32s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "%time knn = experiment(KNeighborsClassifier(n_neighbors=3, weights='distance'), X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
