{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entreno en ogle-3 y veo que detecte en ogle 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# sns.set()\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from libs.container import Container\n",
    "from libs.display import d\n",
    "from libs.experiment import KFoldExperiment, WithAnotherExperiment, roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cat_types = pd.read_pickle(\n",
    "    \"data/ogle3_only/all_cat_types.pkl\")\n",
    "\n",
    "def o4_types(i):\n",
    "    t = all_cat_types[all_cat_types.id == i].vs_type.values[0]\n",
    "    if t == \"\":\n",
    "        return 0\n",
    "    if t.startswith(\"RRLyr-\"):\n",
    "        return 1\n",
    "    return 2\n",
    "\n",
    "class ResultCollector(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.r = {}\n",
    "    \n",
    "    def prop_fp(self, result, size, train, test, force=False):\n",
    "        key = size, train, test\n",
    "        \n",
    "        if force or key not in self.r:\n",
    "\n",
    "            df = pd.DataFrame({\n",
    "                \"o3_cls\": result.y_test_real,\n",
    "                \"o3_pred\": result.predictions,\n",
    "                \"id\": result.ids})\n",
    "\n",
    "            total = len(df)\n",
    "\n",
    "            df = df[(df.o3_pred == 1) & (df.o3_cls == 0)] \n",
    "\n",
    "            df[\"o4_cls\"] = df.id.apply(o4_types)\n",
    "            vstars = df[df.o4_cls != 0]\n",
    "            rr = df[df.o4_cls == 1]\n",
    "\n",
    "            prop_vstars = len(vstars) / float(total)\n",
    "            prop_rrlyrae = len(rr) / float(total)\n",
    "            self.r[key] = prop_vstars, prop_rrlyrae\n",
    "        \n",
    "        return self.r[key]\n",
    "\n",
    "collector = ResultCollector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_pickle(\"data/ogle3_only/scaled/s20k.pkl\")\n",
    "sample[\"o4_type\"] = sample.id.apply(lambda i: o4_types(i))\n",
    "sample[\"tile\"] = sample[\"id\"].apply(lambda i: \"b\" + str(i)[1:4])\n",
    "sample[\"cls\"] = sample.vs_type.apply(lambda x: 0 if x == \"\" else 1)\n",
    "\n",
    "\n",
    "no_features = [\n",
    "    \"id\", \"vs_catalog\", \"vs_type\", \n",
    "    \"ra_k\", \"dec_k\", \"tile\", \"cls\", \"o4_type\"] \n",
    "X_columns = [c for c in sample.columns if c not in no_features]\n",
    "\n",
    "grouped = sample.groupby(\"tile\")\n",
    "data_big = Container({k: grouped.get_group(k).copy() for k in grouped.groups.keys()})\n",
    "\n",
    "del grouped, sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_pickle(\"data/ogle3_only/scaled/s5k.pkl\")\n",
    "sample[\"o4_type\"] = sample.id.apply(lambda i: o4_types(i))\n",
    "sample[\"tile\"] = sample[\"id\"].apply(lambda i: \"b\" + str(i)[1:4])\n",
    "sample[\"cls\"] = sample.vs_type.apply(lambda x: 0 if x == \"\" else 1)\n",
    "\n",
    "grouped = sample.groupby(\"tile\")\n",
    "data_mid = Container({k: grouped.get_group(k).copy() for k in grouped.groups.keys()})\n",
    "\n",
    "del grouped, sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_pickle(\"data/ogle3_only/scaled/s2_5k.pkl\")\n",
    "sample[\"o4_type\"] = sample.id.apply(lambda i: o4_types(i))\n",
    "sample[\"tile\"] = sample[\"id\"].apply(lambda i: \"b\" + str(i)[1:4])\n",
    "sample[\"cls\"] = sample.vs_type.apply(lambda x: 0 if x == \"\" else 1)\n",
    "\n",
    "grouped = sample.groupby(\"tile\")\n",
    "data_small = Container({k: grouped.get_group(k).copy() for k in grouped.groups.keys()})\n",
    "\n",
    "del grouped, sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = {0:0, 1:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.99      0.98      2489\n",
      "        1.0       0.94      0.85      0.89       423\n",
      "\n",
      "avg / total       0.97      0.97      0.97      2912\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b278 (TRAIN) Vs. b262 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      2495\n",
      "          1       0.97      0.85      0.90       296\n",
      "\n",
      "avg / total       0.98      0.98      0.98      2791\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b278 (TRAIN) Vs. b263 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      2500\n",
      "          1       0.96      0.86      0.91       305\n",
      "\n",
      "avg / total       0.98      0.98      0.98      2805\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b278 (TRAIN) Vs. b261 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      2497\n",
      "          1       0.94      0.89      0.91       221\n",
      "\n",
      "avg / total       0.99      0.99      0.99      2718\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b278 (TRAIN) Vs. b264 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99      2498\n",
      "          1       0.95      0.92      0.93       294\n",
      "\n",
      "avg / total       0.99      0.99      0.99      2792\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b261 (TRAIN) Vs. b262 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99      2495\n",
      "          1       0.99      0.77      0.86       296\n",
      "\n",
      "avg / total       0.97      0.97      0.97      2791\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b261 (TRAIN) Vs. b263 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99      2500\n",
      "          1       0.98      0.79      0.88       305\n",
      "\n",
      "avg / total       0.98      0.98      0.97      2805\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b261 (TRAIN) Vs. b278 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97      2489\n",
      "          1       0.97      0.68      0.80       423\n",
      "\n",
      "avg / total       0.95      0.95      0.95      2912\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b261 (TRAIN) Vs. b264 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      2498\n",
      "          1       0.98      0.86      0.92       294\n",
      "\n",
      "avg / total       0.98      0.98      0.98      2792\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b278 + b261 (TRAIN) Vs. b262 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      2495\n",
      "          1       0.98      0.85      0.91       296\n",
      "\n",
      "avg / total       0.98      0.98      0.98      2791\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b278 + b261 (TRAIN) Vs. b263 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      2500\n",
      "          1       0.98      0.86      0.92       305\n",
      "\n",
      "avg / total       0.98      0.98      0.98      2805\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b278 + b261 (TRAIN) Vs. b264 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      2498\n",
      "          1       0.97      0.93      0.95       294\n",
      "\n",
      "avg / total       0.99      0.99      0.99      2792\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b278 + b261 + b264 (TRAIN) Vs. b262 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      2495\n",
      "          1       0.98      0.86      0.92       296\n",
      "\n",
      "avg / total       0.98      0.98      0.98      2791\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b278 + b261 + b264 (TRAIN) Vs. b263 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      2500\n",
      "          1       0.98      0.86      0.91       305\n",
      "\n",
      "avg / total       0.98      0.98      0.98      2805\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "CPU times: user 3min 15s, sys: 524 ms, total: 3min 15s\n",
      "Wall time: 3min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = data_small\n",
    "data_name = \"small\"\n",
    "\n",
    "rf = KFoldExperiment(\n",
    "    clf=RandomForestClassifier(n_estimators=500, criterion=\"entropy\"), clsnum=cls, \n",
    "    data=data, pcls=1, ncls=0, X_columns=X_columns, y_column=\"cls\")\n",
    "rf = rf(\"b278\", nfolds=10)\n",
    "collector.prop_fp(rf, data_name,\"b278\", \"k-fold\")\n",
    "\n",
    "rf = WithAnotherExperiment(\n",
    "    clf=RandomForestClassifier(n_estimators=500, criterion=\"entropy\"), \n",
    "    clsnum=cls, data=data, pcls=1, ncls=0, X_columns=X_columns, y_column=\"cls\")\n",
    "rf = rf(\"b278\")\n",
    "for result in rf:\n",
    "    collector.prop_fp(result, data_name,\"b278\", result.test_name)\n",
    "    \n",
    "rf = WithAnotherExperiment(\n",
    "    clf=RandomForestClassifier(n_estimators=500, criterion=\"entropy\"), \n",
    "    clsnum=cls, data=data, pcls=1, ncls=0, X_columns=X_columns, y_column=\"cls\")\n",
    "rf = rf(\"b261\")\n",
    "for result in rf:\n",
    "    collector.prop_fp(result, data_name,\"b261\", result.test_name)\n",
    "    \n",
    "rf = WithAnotherExperiment(\n",
    "    clf=RandomForestClassifier(n_estimators=500, criterion=\"entropy\"), \n",
    "    clsnum=cls, data=data, pcls=1, ncls=0, X_columns=X_columns, y_column=\"cls\")\n",
    "rf = rf([\"b278\", \"b261\"])\n",
    "for result in rf:\n",
    "    collector.prop_fp(result, data_name,\"b261 + b278\", result.test_name)\n",
    "    \n",
    "rf = WithAnotherExperiment(\n",
    "    clf=RandomForestClassifier(n_estimators=500, criterion=\"entropy\"), \n",
    "    clsnum=cls, data=data, pcls=1, ncls=0, X_columns=X_columns, y_column=\"cls\")\n",
    "rf = rf([\"b278\", \"b261\", \"b264\"])\n",
    "for result in rf:\n",
    "    collector.prop_fp(result, data_name,\"b261 + b264 + b278\", result.test_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.99      0.99      4983\n",
      "        1.0       0.92      0.78      0.85       423\n",
      "\n",
      "avg / total       0.98      0.98      0.98      5406\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b278 (TRAIN) Vs. b262 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      4992\n",
      "          1       0.97      0.79      0.87       296\n",
      "\n",
      "avg / total       0.99      0.99      0.99      5288\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b278 (TRAIN) Vs. b263 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      4997\n",
      "          1       0.97      0.78      0.86       305\n",
      "\n",
      "avg / total       0.99      0.99      0.98      5302\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b278 (TRAIN) Vs. b261 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00      4991\n",
      "          1       0.93      0.84      0.88       221\n",
      "\n",
      "avg / total       0.99      0.99      0.99      5212\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b278 (TRAIN) Vs. b264 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      4998\n",
      "          1       0.96      0.84      0.90       294\n",
      "\n",
      "avg / total       0.99      0.99      0.99      5292\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b261 (TRAIN) Vs. b262 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      4992\n",
      "          1       0.98      0.73      0.84       296\n",
      "\n",
      "avg / total       0.98      0.98      0.98      5288\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b261 (TRAIN) Vs. b263 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99      4997\n",
      "          1       0.99      0.73      0.84       305\n",
      "\n",
      "avg / total       0.98      0.98      0.98      5302\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b261 (TRAIN) Vs. b278 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.99      4983\n",
      "          1       0.97      0.68      0.80       423\n",
      "\n",
      "avg / total       0.97      0.97      0.97      5406\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b261 (TRAIN) Vs. b264 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      4998\n",
      "          1       0.99      0.77      0.86       294\n",
      "\n",
      "avg / total       0.99      0.99      0.99      5292\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b278 + b261 (TRAIN) Vs. b262 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      4992\n",
      "          1       0.97      0.78      0.87       296\n",
      "\n",
      "avg / total       0.99      0.99      0.99      5288\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b278 + b261 (TRAIN) Vs. b263 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      4997\n",
      "          1       0.98      0.78      0.87       305\n",
      "\n",
      "avg / total       0.99      0.99      0.99      5302\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b278 + b261 (TRAIN) Vs. b264 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      4998\n",
      "          1       0.97      0.84      0.90       294\n",
      "\n",
      "avg / total       0.99      0.99      0.99      5292\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b278 + b261 + b264 (TRAIN) Vs. b262 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      4992\n",
      "          1       0.96      0.81      0.88       296\n",
      "\n",
      "avg / total       0.99      0.99      0.99      5288\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b278 + b261 + b264 (TRAIN) Vs. b263 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99      4997\n",
      "          1       0.98      0.79      0.87       305\n",
      "\n",
      "avg / total       0.99      0.99      0.99      5302\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "CPU times: user 5min 17s, sys: 1.02 s, total: 5min 18s\n",
      "Wall time: 5min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = data_mid\n",
    "data_name = \"mid\"\n",
    "\n",
    "rf = KFoldExperiment(\n",
    "    clf=RandomForestClassifier(n_estimators=500, criterion=\"entropy\"), clsnum=cls, \n",
    "    data=data, pcls=1, ncls=0, X_columns=X_columns, y_column=\"cls\")\n",
    "rf = rf(\"b278\", nfolds=10)\n",
    "collector.prop_fp(rf, data_name,\"b278\", \"k-fold\")\n",
    "\n",
    "rf = WithAnotherExperiment(\n",
    "    clf=RandomForestClassifier(n_estimators=500, criterion=\"entropy\"), \n",
    "    clsnum=cls, data=data, pcls=1, ncls=0, X_columns=X_columns, y_column=\"cls\")\n",
    "rf = rf(\"b278\")\n",
    "for result in rf:\n",
    "    collector.prop_fp(result, data_name,\"b278\", result.test_name)\n",
    "    \n",
    "rf = WithAnotherExperiment(\n",
    "    clf=RandomForestClassifier(n_estimators=500, criterion=\"entropy\"), \n",
    "    clsnum=cls, data=data, pcls=1, ncls=0, X_columns=X_columns, y_column=\"cls\")\n",
    "rf = rf(\"b261\")\n",
    "for result in rf:\n",
    "    collector.prop_fp(result, data_name,\"b261\", result.test_name)\n",
    "    \n",
    "rf = WithAnotherExperiment(\n",
    "    clf=RandomForestClassifier(n_estimators=500, criterion=\"entropy\"), \n",
    "    clsnum=cls, data=data, pcls=1, ncls=0, X_columns=X_columns, y_column=\"cls\")\n",
    "rf = rf([\"b278\", \"b261\"])\n",
    "for result in rf:\n",
    "    collector.prop_fp(result, data_name,\"b261 + b278\", result.test_name)\n",
    "    \n",
    "rf = WithAnotherExperiment(\n",
    "    clf=RandomForestClassifier(n_estimators=500, criterion=\"entropy\"), \n",
    "    clsnum=cls, data=data, pcls=1, ncls=0, X_columns=X_columns, y_column=\"cls\")\n",
    "rf = rf([\"b278\", \"b261\", \"b264\"])\n",
    "for result in rf:\n",
    "    collector.prop_fp(result, data_name,\"b261 + b264 + b278\", result.test_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.99      1.00      1.00     19931\n",
      "        1.0       0.95      0.65      0.77       423\n",
      "\n",
      "avg / total       0.99      0.99      0.99     20354\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b278 (TRAIN) Vs. b262 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     19951\n",
      "          1       0.97      0.67      0.79       296\n",
      "\n",
      "avg / total       0.99      0.99      0.99     20247\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b278 (TRAIN) Vs. b263 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00     19988\n",
      "          1       0.93      0.67      0.77       305\n",
      "\n",
      "avg / total       0.99      0.99      0.99     20293\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b278 (TRAIN) Vs. b261 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     19972\n",
      "          1       0.97      0.75      0.84       221\n",
      "\n",
      "avg / total       1.00      1.00      1.00     20193\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b278 (TRAIN) Vs. b264 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     19995\n",
      "          1       0.94      0.74      0.83       294\n",
      "\n",
      "avg / total       1.00      1.00      1.00     20289\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b261 (TRAIN) Vs. b262 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00     19951\n",
      "          1       0.98      0.63      0.77       296\n",
      "\n",
      "avg / total       0.99      0.99      0.99     20247\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b261 (TRAIN) Vs. b263 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00     19988\n",
      "          1       0.96      0.64      0.76       305\n",
      "\n",
      "avg / total       0.99      0.99      0.99     20293\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b261 (TRAIN) Vs. b278 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      1.00     19931\n",
      "          1       0.96      0.57      0.72       423\n",
      "\n",
      "avg / total       0.99      0.99      0.99     20354\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b261 (TRAIN) Vs. b264 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     19995\n",
      "          1       0.96      0.70      0.81       294\n",
      "\n",
      "avg / total       1.00      1.00      0.99     20289\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b278 + b261 (TRAIN) Vs. b262 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     19951\n",
      "          1       0.98      0.68      0.80       296\n",
      "\n",
      "avg / total       1.00      1.00      0.99     20247\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b278 + b261 (TRAIN) Vs. b263 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     19988\n",
      "          1       0.94      0.69      0.80       305\n",
      "\n",
      "avg / total       0.99      0.99      0.99     20293\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b278 + b261 (TRAIN) Vs. b264 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     19995\n",
      "          1       0.94      0.75      0.84       294\n",
      "\n",
      "avg / total       1.00      1.00      1.00     20289\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b278 + b261 + b264 (TRAIN) Vs. b262 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     19951\n",
      "          1       0.97      0.71      0.82       296\n",
      "\n",
      "avg / total       1.00      1.00      1.00     20247\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "b278 + b261 + b264 (TRAIN) Vs. b263 (TEST)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     19988\n",
      "          1       0.94      0.71      0.81       305\n",
      "\n",
      "avg / total       0.99      0.99      0.99     20293\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "CPU times: user 17min 46s, sys: 1.59 s, total: 17min 47s\n",
      "Wall time: 17min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data = data_big\n",
    "data_name = \"big\"\n",
    "\n",
    "rf = KFoldExperiment(\n",
    "    clf=RandomForestClassifier(n_estimators=500, criterion=\"entropy\"), clsnum=cls, \n",
    "    data=data, pcls=1, ncls=0, X_columns=X_columns, y_column=\"cls\")\n",
    "rf = rf(\"b278\", nfolds=10)\n",
    "collector.prop_fp(rf, data_name,\"b278\", \"k-fold\")\n",
    "\n",
    "rf = WithAnotherExperiment(\n",
    "    clf=RandomForestClassifier(n_estimators=500, criterion=\"entropy\"), \n",
    "    clsnum=cls, data=data, pcls=1, ncls=0, X_columns=X_columns, y_column=\"cls\")\n",
    "rf = rf(\"b278\")\n",
    "for result in rf:\n",
    "    collector.prop_fp(result, data_name,\"b278\", result.test_name)\n",
    "    \n",
    "rf = WithAnotherExperiment(\n",
    "    clf=RandomForestClassifier(n_estimators=500, criterion=\"entropy\"), \n",
    "    clsnum=cls, data=data, pcls=1, ncls=0, X_columns=X_columns, y_column=\"cls\")\n",
    "rf = rf(\"b261\")\n",
    "for result in rf:\n",
    "    collector.prop_fp(result, data_name,\"b261\", result.test_name)\n",
    "    \n",
    "rf = WithAnotherExperiment(\n",
    "    clf=RandomForestClassifier(n_estimators=500, criterion=\"entropy\"), \n",
    "    clsnum=cls, data=data, pcls=1, ncls=0, X_columns=X_columns, y_column=\"cls\")\n",
    "rf = rf([\"b278\", \"b261\"])\n",
    "for result in rf:\n",
    "    collector.prop_fp(result, data_name,\"b261 + b278\", result.test_name)\n",
    "    \n",
    "rf = WithAnotherExperiment(\n",
    "    clf=RandomForestClassifier(n_estimators=500, criterion=\"entropy\"), \n",
    "    clsnum=cls, data=data, pcls=1, ncls=0, X_columns=X_columns, y_column=\"cls\")\n",
    "rf = rf([\"b278\", \"b261\", \"b264\"])\n",
    "for result in rf:\n",
    "    collector.prop_fp(result, data_name,\"b261 + b264 + b278\", result.test_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"coso.npy\", [collector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "collector = np.load(\"coso.npy\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = [\n",
    "    [\"b278\", [\n",
    "        \"k-fold\",\n",
    "        \"b261\",\n",
    "        \"b262\",\n",
    "        \"b263\",\n",
    "        \"b264\"]],\n",
    "    [\"b261\", [\n",
    "        \"b262\",\n",
    "        \"b263\",\n",
    "        \"b264\",\n",
    "        \"b278\"]],\n",
    "    [\"b261 + b278\", [\n",
    "        \"b262\",\n",
    "        \"b263\",\n",
    "        \"b264\"]],\n",
    "    [\"b261 + b264 + b278\", [\n",
    "        \"b262\",\n",
    "        \"b263\"]]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('big', 'b261', 'b262'): (4.939003309132217e-05, 0.0),\n",
       " ('big', 'b261', 'b263'): (0.00039422460947124624, 0.0),\n",
       " ('big', 'b261', 'b264'): (0.00024643895707033366, 0.0),\n",
       " ('big', 'b261', 'b278'): (0.00029478235236317184, 0.0),\n",
       " ('big', 'b261 + b264 + b278', 'b262'): (4.939003309132217e-05, 0.0),\n",
       " ('big', 'b261 + b264 + b278', 'b263'): (0.0005420588380229636, 0.0),\n",
       " ('big', 'b261 + b278', 'b262'): (4.939003309132217e-05, 0.0),\n",
       " ('big', 'b261 + b278', 'b263'): (0.0004927807618390578, 0.0),\n",
       " ('big', 'b261 + b278', 'b264'): (0.0002957267484844004, 0.0),\n",
       " ('big', 'b278', 'b261'): (0.0001980884464913584, 4.95221116228396e-05),\n",
       " ('big', 'b278', 'b262'): (4.939003309132217e-05, 0.0),\n",
       " ('big', 'b278', 'b263'): (0.0005420588380229636, 0.0),\n",
       " ('big', 'b278', 'b264'): (0.0002957267484844004, 0.0),\n",
       " ('big', 'b278', 'k-fold'): (0.00029478235236317184, 0.0),\n",
       " ('mid', 'b261', 'b262'): (0.0, 0.0),\n",
       " ('mid', 'b261', 'b263'): (0.0003772161448509996, 0.0),\n",
       " ('mid', 'b261', 'b264'): (0.0001889644746787604, 0.0),\n",
       " ('mid', 'b261', 'b278'): (0.0003699593044765076, 0.0),\n",
       " ('mid', 'b261 + b264 + b278', 'b262'): (0.00018910741301059002, 0.0),\n",
       " ('mid', 'b261 + b264 + b278', 'b263'): (0.0003772161448509996, 0.0),\n",
       " ('mid', 'b261 + b278', 'b262'): (0.00018910741301059002, 0.0),\n",
       " ('mid', 'b261 + b278', 'b263'): (0.0003772161448509996, 0.0),\n",
       " ('mid', 'b261 + b278', 'b264'): (0.0001889644746787604, 0.0),\n",
       " ('mid', 'b278', 'b261'): (0.0007674597083653108, 0.0),\n",
       " ('mid', 'b278', 'b262'): (0.00018910741301059002, 0.0),\n",
       " ('mid', 'b278', 'b263'): (0.0003772161448509996, 0.0),\n",
       " ('mid', 'b278', 'b264'): (0.0001889644746787604, 0.0),\n",
       " ('mid', 'b278', 'k-fold'): (0.0005549389567147614, 0.0),\n",
       " ('small', 'b261', 'b262'): (0.00035829451809387314, 0.0),\n",
       " ('small', 'b261', 'b263'): (0.00035650623885918, 0.0),\n",
       " ('small', 'b261', 'b264'): (0.0007163323782234957, 0.0),\n",
       " ('small', 'b261', 'b278'): (0.0010302197802197802, 0.0),\n",
       " ('small', 'b261 + b264 + b278', 'b262'): (0.00035829451809387314, 0.0),\n",
       " ('small', 'b261 + b264 + b278', 'b263'): (0.00035650623885918, 0.0),\n",
       " ('small', 'b261 + b278', 'b262'): (0.00035829451809387314, 0.0),\n",
       " ('small', 'b261 + b278', 'b263'): (0.00035650623885918, 0.0),\n",
       " ('small', 'b261 + b278', 'b264'): (0.0007163323782234957, 0.0),\n",
       " ('small', 'b278', 'b261'): (0.0014716703458425313, 0.0),\n",
       " ('small', 'b278', 'b262'): (0.00035829451809387314, 0.0),\n",
       " ('small', 'b278', 'b263'): (0.00035650623885918, 0.0),\n",
       " ('small', 'b278', 'b264'): (0.0007163323782234957, 0.0),\n",
       " ('small', 'b278', 'k-fold'): (0.0010302197802197802, 0.0)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collector.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = {}\n",
    "for size in \"small mid big\".split():\n",
    "    props = []\n",
    "    for train, tests in rows:\n",
    "        for test in tests:\n",
    "            key = (size, train, test)\n",
    "            prop = collector.r[key][0]\n",
    "            props.append(prop)\n",
    "    columns[size] = props\n",
    "    \n",
    "trainc, testc = [], []\n",
    "for train, tests in rows:\n",
    "    for test in tests:\n",
    "        trainc.append(train)\n",
    "        testc.append(test)\n",
    "        train = \"\"\n",
    "columns.update(train=trainc, test=testc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrr}\n",
      "\\toprule\n",
      "              train &    test &     small &       mid &       big \\\\\n",
      "\\midrule\n",
      "               b278 &  k-fold &  0.001030 &  0.000555 &  0.000295 \\\\\n",
      "                    &    b261 &  0.001472 &  0.000767 &  0.000198 \\\\\n",
      "                    &    b262 &  0.000358 &  0.000189 &  0.000049 \\\\\n",
      "                    &    b263 &  0.000357 &  0.000377 &  0.000542 \\\\\n",
      "                    &    b264 &  0.000716 &  0.000189 &  0.000296 \\\\\n",
      "               b261 &    b262 &  0.000358 &  0.000000 &  0.000049 \\\\\n",
      "                    &    b263 &  0.000357 &  0.000377 &  0.000394 \\\\\n",
      "                    &    b264 &  0.000716 &  0.000189 &  0.000246 \\\\\n",
      "                    &    b278 &  0.001030 &  0.000370 &  0.000295 \\\\\n",
      "        b261 + b278 &    b262 &  0.000358 &  0.000189 &  0.000049 \\\\\n",
      "                    &    b263 &  0.000357 &  0.000377 &  0.000493 \\\\\n",
      "                    &    b264 &  0.000716 &  0.000189 &  0.000296 \\\\\n",
      " b261 + b264 + b278 &    b262 &  0.000358 &  0.000189 &  0.000049 \\\\\n",
      "                    &    b263 &  0.000357 &  0.000377 &  0.000542 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print pd.DataFrame(columns)[\"train test small mid big\".split()].to_latex(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
