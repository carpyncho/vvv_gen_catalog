{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escalado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# sns.set()\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s20k = pd.read_pickle(\"data/ogle3_only/sample_ogle3_20000.pkl.bz2\")\n",
    "s2_5k = pd.read_pickle(\"data/ogle3_only/sample_ogle3_2500.pkl.bz2\")\n",
    "s5k = pd.read_pickle(\"data/ogle3_only/sample_ogle3_5000.pkl.bz2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removemos los features que no queremos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s20k[\"AmplitudeJH\"] = s20k.AmplitudeJ - s20k.AmplitudeH\n",
    "s20k[\"AmplitudeJK\"] = s20k.AmplitudeJ - s20k.Amplitude\n",
    "\n",
    "s5k[\"AmplitudeJH\"] = s5k.AmplitudeJ - s5k.AmplitudeH\n",
    "s5k[\"AmplitudeJK\"] = s5k.AmplitudeJ - s5k.Amplitude\n",
    "\n",
    "s2_5k[\"AmplitudeJH\"] = s2_5k.AmplitudeJ - s2_5k.AmplitudeH\n",
    "s2_5k[\"AmplitudeJK\"] = s2_5k.AmplitudeJ - s2_5k.Amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [\n",
    "    'Gskew', # has nan in the rlyrae stars\n",
    "    \"scls_h\", \"scls_j\", \"scls_k\",  # no nos sirve\n",
    "    \"AndersonDarling\", \"StetsonJ\", \"StetsonK\"\n",
    "] + [s for s in s20k.columns if s.startswith(\"Freq2_\") or s.startswith(\"Freq3_\") ] # only the first period is important\n",
    "to_keep = [c for c in s20k.columns if c not in to_drop]\n",
    "\n",
    "s20k = s20k[to_keep]\n",
    "s5k = s5k[to_keep]\n",
    "s2_5k = s2_5k = s2_5k[to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removemos filas que tengan un nan en `period_fit` pero antes nos fijamos que ninguna sea una RR-Lyrae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['']\n",
      "['']\n",
      "['']\n"
     ]
    }
   ],
   "source": [
    "print s20k[s20k.Period_fit.isnull()].vs_type.unique()\n",
    "print s5k[s5k.Period_fit.isnull()].vs_type.unique()\n",
    "print s2_5k[s2_5k.Period_fit.isnull()].vs_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s20k = s20k.dropna()\n",
    "s5k = s5k.dropna()\n",
    "s2_5k = s2_5k.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos que columnas tienen un valor infinito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Period_fit\n"
     ]
    }
   ],
   "source": [
    "for x in s20k.columns:\n",
    "    if s20k[x].dtype == object:\n",
    "        continue\n",
    "    if np.isinf(s20k[x].values).sum() + np.isinf(s5k[x].values).sum() + np.isinf(s2_5k[x].values).sum():\n",
    "        print x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como period_fit es un feature que me interesa, verificamos que cantidad de filas son las afectadas\n",
    "y si hay alguna con RRLyraes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 62)\n",
      "(6, 62)\n",
      "(26, 62)\n",
      "['']\n",
      "['']\n",
      "['']\n"
     ]
    }
   ],
   "source": [
    "print s2_5k[np.isinf(s2_5k.Period_fit.values)].shape\n",
    "print s5k[np.isinf(s5k.Period_fit.values)].shape\n",
    "print s20k[np.isinf(s20k.Period_fit.values)].shape\n",
    "\n",
    "print s2_5k[np.isinf(s2_5k.Period_fit.values)].vs_type.unique()\n",
    "print s5k[np.isinf(s5k.Period_fit.values)].vs_type.unique()\n",
    "print s20k[np.isinf(s20k.Period_fit.values)].vs_type.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Son pocas filas y no hay rrlyraes... las borramos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s20k = s20k[~np.isinf(s20k.Period_fit.values)]\n",
    "s5k = s5k[~np.isinf(s5k.Period_fit.values)]\n",
    "s2_5k = s2_5k[~np.isinf(s2_5k.Period_fit.values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ahora almacenamos tod esto limpio para futuros usos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s20k.to_pickle(\"data/ogle3_only/nonull/s20k.pkl.bz2\", compression=\"bz2\")\n",
    "s5k.to_pickle(\"data/ogle3_only/nonull/s5k.pkl.bz2\", compression=\"bz2\")\n",
    "s2_5k.to_pickle(\"data/ogle3_only/nonull/s2_5k.pkl.bz2\", compression=\"bz2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ahora normalizamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_features = [\"id\", \"vs_catalog\", \"vs_type\", \"ra_k\", \"dec_k\", ] \n",
    "X_columns = [c for c in s20k.columns if c not in no_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "splited = {idx+1: list(s) for idx, s in enumerate(np.array_split(sorted(X_columns), 15))}\n",
    "maxs = max(map(len, splited.values()))\n",
    "for v in splited.values():\n",
    "    while len(v) < maxs:\n",
    "        v.append(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llll}\n",
      "\\toprule\n",
      "                           0 &                                1 &                            2 &                            3 \\\\\n",
      "\\midrule\n",
      "                   Amplitude &                       AmplitudeH &                   AmplitudeJ &                  AmplitudeJH \\\\\n",
      "                 AmplitudeJK &                   Autocor\\_length &                   Beyond1Std &                     CAR\\_mean \\\\\n",
      "                   CAR\\_sigma &                          CAR\\_tau &                          Con &                        Eta\\_e \\\\\n",
      "    FluxPercentileRatioMid20 &         FluxPercentileRatioMid35 &     FluxPercentileRatioMid50 &     FluxPercentileRatioMid65 \\\\\n",
      "    FluxPercentileRatioMid80 &      Freq1\\_harmonics\\_amplitude\\_0 &  Freq1\\_harmonics\\_amplitude\\_1 &  Freq1\\_harmonics\\_amplitude\\_2 \\\\\n",
      " Freq1\\_harmonics\\_amplitude\\_3 &      Freq1\\_harmonics\\_rel\\_phase\\_0 &  Freq1\\_harmonics\\_rel\\_phase\\_1 &  Freq1\\_harmonics\\_rel\\_phase\\_2 \\\\\n",
      " Freq1\\_harmonics\\_rel\\_phase\\_3 &                      LinearTrend &                     MaxSlope &                         Mean \\\\\n",
      "                Meanvariance &                     MedianAbsDev &                    MedianBRP &               PairSlopeTrend \\\\\n",
      "            PercentAmplitude &  PercentDifferenceFluxPercentile &                     PeriodLS &                   Period\\_fit \\\\\n",
      "                      Psi\\_CS &                          Psi\\_eta &                          Q31 &                          Rcs \\\\\n",
      "                        Skew &                    SmallKurtosis &                          Std &                       c89\\_c3 \\\\\n",
      "                c89\\_hk\\_color &                     c89\\_jh\\_color &                 c89\\_jk\\_color &                       c89\\_m2 \\\\\n",
      "                      c89\\_m4 &                              cnt &                       n09\\_c3 &                              \\\\\n",
      "                n09\\_hk\\_color &                     n09\\_jh\\_color &                 n09\\_jk\\_color &                              \\\\\n",
      "                      n09\\_m2 &                           n09\\_m4 &                         ppmb &                              \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feats = pd.DataFrame(splited).T\n",
    "feats\n",
    "print feats.to_latex(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbcabral/.conda/envs/carpyncho3/lib/python2.7/site-packages/numpy/core/_methods.py:105: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n"
     ]
    }
   ],
   "source": [
    "scaler_20k = StandardScaler()\n",
    "norm_s20k = s20k.copy()\n",
    "norm_s20k[X_columns] = scaler_20k.fit_transform(s20k[X_columns])\n",
    "pickle.dump(scaler_20k, open(\"data/ogle3_only/scalers/scaler_20k.pkl\", \"wb\"))\n",
    "norm_s20k.to_pickle(\"data/ogle3_only/scaled/s20k.pkl.bz2\", compression=\"bz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_5k = StandardScaler()\n",
    "norm_s5k = s5k.copy()\n",
    "norm_s5k[X_columns] = scaler_5k.fit_transform(s5k[X_columns])\n",
    "pickle.dump(scaler_5k, open(\"data/ogle3_only/scalers/scaler_5k.pkl\", \"wb\"))\n",
    "norm_s5k.to_pickle(\"data/ogle3_only/scaled/s5k.pkl.bz2\", compression=\"bz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_2_5k = StandardScaler()\n",
    "norm_s2_5k = s2_5k.copy()\n",
    "norm_s2_5k[X_columns] = scaler_2_5k.fit_transform(s2_5k[X_columns])\n",
    "pickle.dump(scaler_2_5k, open(\"data/ogle3_only/scalers/scaler_2_5k.pkl\", \"wb\"))\n",
    "norm_s2_5k.to_pickle(\"data/ogle3_only/scaled/s2_5k.pkl.bz2\", compression=\"bz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = {k: {\"Tile\": k} for k in \"b261 b262 b263 b264 b278\".split()}\n",
    "    \n",
    "for nombre, s in zip([\"Chica\", \"Mediana\", \"Grande\"] , [s2_5k,s5k,s20k]):\n",
    "    s = s.copy()\n",
    "    s[\"tile\"] = s[\"id\"].apply(lambda i: \"b\" + str(i)[1:4])\n",
    "    grouped = s.groupby(\"tile\")\n",
    "    data = {k: grouped.get_group(k).copy() for k in grouped.groups.keys()}\n",
    "    for tile, df in data.items():\n",
    "        row = rows[tile]\n",
    "        row.update({\n",
    "            nombre : len(df[df.vs_type.str.contains(\"\")]),\n",
    "            \"RR-Lyrae\": len(df[df.vs_type.str.startswith(\"RRLyr\")]),\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      " Tile &  Chica &  Mediana &  Grande &  RR-Lyrae \\\\\n",
      "\\midrule\n",
      " b261 &   2718 &     5212 &   20193 &       221 \\\\\n",
      " b262 &   2791 &     5288 &   20247 &       296 \\\\\n",
      " b263 &   2805 &     5302 &   20293 &       305 \\\\\n",
      " b264 &   2792 &     5292 &   20289 &       294 \\\\\n",
      " b278 &   2912 &     5406 &   20354 &       423 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print pd.DataFrame(\n",
    "    [v for v in rows.values()]\n",
    ")[\n",
    "    \"Tile Chica Mediana Grande RR-Lyrae\".split()\n",
    "].sort_values(\"Tile\").to_latex(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
