{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escalado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "% matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# sns.set()\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "s20k = pd.read_pickle(\"data/ogle3_only/sample_ogle3_20000.pkl\")\n",
    "s2_5k = pd.read_pickle(\"data/ogle3_only/sample_ogle3_2500.pkl\")\n",
    "s5k = pd.read_pickle(\"data/ogle3_only/sample_ogle3_5000.pkl\")"
=======
    "s20k = pd.read_pickle(\"data/ogle3_only/sample_ogle3_20000.pkl.bz2\")\n",
    "s2_5k = pd.read_pickle(\"data/ogle3_only/sample_ogle3_2500.pkl.bz2\")\n",
    "s5k = pd.read_pickle(\"data/ogle3_only/sample_ogle3_5000.pkl.bz2\")"
>>>>>>> 355f3f69c644942bd910a5af461ce51c9b5f1bcd
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removemos los features que no queremos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
=======
    "s20k[\"AmplitudeJH\"] = s20k.AmplitudeJ - s20k.AmplitudeH\n",
    "s20k[\"AmplitudeJK\"] = s20k.AmplitudeJ - s20k.Amplitude\n",
    "\n",
    "s5k[\"AmplitudeJH\"] = s5k.AmplitudeJ - s5k.AmplitudeH\n",
    "s5k[\"AmplitudeJK\"] = s5k.AmplitudeJ - s5k.Amplitude\n",
    "\n",
    "s2_5k[\"AmplitudeJH\"] = s2_5k.AmplitudeJ - s2_5k.AmplitudeH\n",
    "s2_5k[\"AmplitudeJK\"] = s2_5k.AmplitudeJ - s2_5k.Amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
>>>>>>> 355f3f69c644942bd910a5af461ce51c9b5f1bcd
    "to_drop = [\n",
    "    'Gskew', # has nan in the rlyrae stars\n",
    "    \"scls_h\", \"scls_j\", \"scls_k\"  # no nos sirve\n",
    "] + [s for s in s20k.columns if s.startswith(\"Freq2_\") or s.startswith(\"Freq3_\") ] # only the first period is important\n",
    "to_keep = [c for c in s20k.columns if c not in to_drop]\n",
    "\n",
    "s20k = s20k[to_keep]\n",
    "s5k = s5k[to_keep]\n",
    "s2_5k = s2_5k = s2_5k[to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removemos filas que tengan un nan en `period_fit` pero antes nos fijamos que ninguna sea una RR-Lyrae"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 6,
>>>>>>> 355f3f69c644942bd910a5af461ce51c9b5f1bcd
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['']\n",
      "['']\n",
      "['']\n"
     ]
    }
   ],
   "source": [
    "print s20k[s20k.Period_fit.isnull()].vs_type.unique()\n",
    "print s5k[s5k.Period_fit.isnull()].vs_type.unique()\n",
    "print s2_5k[s2_5k.Period_fit.isnull()].vs_type.unique()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 7,
>>>>>>> 355f3f69c644942bd910a5af461ce51c9b5f1bcd
   "metadata": {},
   "outputs": [],
   "source": [
    "s20k = s20k.dropna()\n",
    "s5k = s5k.dropna()\n",
    "s2_5k = s2_5k.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluamos que columnas tienen un valor infinito"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 8,
>>>>>>> 355f3f69c644942bd910a5af461ce51c9b5f1bcd
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Period_fit\n"
     ]
    }
   ],
   "source": [
    "for x in s20k.columns:\n",
    "    if s20k[x].dtype == object:\n",
    "        continue\n",
    "    if np.isinf(s20k[x].values).sum() + np.isinf(s5k[x].values).sum() + np.isinf(s2_5k[x].values).sum():\n",
    "        print x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como period_fit es un feature que me interesa, verificamos que cantidad de filas son las afectadas\n",
    "y si hay alguna con RRLyraes"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 9,
>>>>>>> 355f3f69c644942bd910a5af461ce51c9b5f1bcd
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "(2, 62)\n",
      "(6, 62)\n",
      "(26, 62)\n",
=======
      "(2, 64)\n",
      "(6, 64)\n",
      "(26, 64)\n",
>>>>>>> 355f3f69c644942bd910a5af461ce51c9b5f1bcd
      "['']\n",
      "['']\n",
      "['']\n"
     ]
    }
   ],
   "source": [
    "print s2_5k[np.isinf(s2_5k.Period_fit.values)].shape\n",
    "print s5k[np.isinf(s5k.Period_fit.values)].shape\n",
    "print s20k[np.isinf(s20k.Period_fit.values)].shape\n",
    "\n",
    "print s2_5k[np.isinf(s2_5k.Period_fit.values)].vs_type.unique()\n",
    "print s5k[np.isinf(s5k.Period_fit.values)].vs_type.unique()\n",
    "print s20k[np.isinf(s20k.Period_fit.values)].vs_type.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Son pocas filas y no hay rrlyraes... las borramos"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 10,
>>>>>>> 355f3f69c644942bd910a5af461ce51c9b5f1bcd
   "metadata": {},
   "outputs": [],
   "source": [
    "s20k = s20k[~np.isinf(s20k.Period_fit.values)]\n",
    "s5k = s5k[~np.isinf(s5k.Period_fit.values)]\n",
    "s2_5k = s2_5k[~np.isinf(s2_5k.Period_fit.values)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
=======
    "ahora almacenamos tod esto limpio para futuros usos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s20k.to_pickle(\"data/ogle3_only/nonull/s20k.pkl.bz2\", compression=\"bz2\")\n",
    "s5k.to_pickle(\"data/ogle3_only/nonull/s5k.pkl.bz2\", compression=\"bz2\")\n",
    "s2_5k.to_pickle(\"data/ogle3_only/nonull/s2_5k.pkl.bz2\", compression=\"bz2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
>>>>>>> 355f3f69c644942bd910a5af461ce51c9b5f1bcd
    "## Ahora normalizamos"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_features = [\"id\", \"vs_catalog\", \"vs_type\", \"ra_k\", \"dec_k\", ] \n",
    "X_columns = [c for c in s20k.columns if c not in no_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "splited = {idx+1: list(s) for idx, s in enumerate(np.array_split(sorted(X_columns), 19))}\n",
    "maxs = max(map(len, splited.values()))\n",
    "for v in splited.values():\n",
    "    while len(v) < maxs:\n",
    "        v.append(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
>>>>>>> 355f3f69c644942bd910a5af461ce51c9b5f1bcd
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Features:\n",
      "\tcnt, Amplitude, AndersonDarling, Autocor_length, Beyond1Std, CAR_mean, CAR_sigma, CAR_tau, Con, Eta_e, FluxPercentileRatioMid20, FluxPercentileRatioMid35, FluxPercentileRatioMid50, FluxPercentileRatioMid65, FluxPercentileRatioMid80, Freq1_harmonics_amplitude_0, Freq1_harmonics_amplitude_1, Freq1_harmonics_amplitude_2, Freq1_harmonics_amplitude_3, Freq1_harmonics_rel_phase_0, Freq1_harmonics_rel_phase_1, Freq1_harmonics_rel_phase_2, Freq1_harmonics_rel_phase_3, LinearTrend, MaxSlope, Mean, Meanvariance, MedianAbsDev, MedianBRP, PairSlopeTrend, PercentAmplitude, PercentDifferenceFluxPercentile, PeriodLS, Period_fit, Psi_CS, Psi_eta, Q31, Rcs, Skew, SmallKurtosis, Std, StetsonK, c89_jk_color, c89_hk_color, c89_jh_color, n09_jk_color, n09_hk_color, n09_jh_color, c89_m2, c89_m4, c89_c3, n09_m2, n09_m4, n09_c3, AmplitudeH, AmplitudeJ, ppmb\n"
=======
      "\\begin{tabular}{llll}\n",
      "\\toprule\n",
      "                           0 &                            1 &                                2 &            3 \\\\\n",
      "\\midrule\n",
      "                   Amplitude &                   AmplitudeH &                       AmplitudeJ &  AmplitudeJH \\\\\n",
      "                 AmplitudeJK &              AndersonDarling &                   Autocor\\_length &   Beyond1Std \\\\\n",
      "                    CAR\\_mean &                    CAR\\_sigma &                          CAR\\_tau &              \\\\\n",
      "                         Con &                        Eta\\_e &         FluxPercentileRatioMid20 &              \\\\\n",
      "    FluxPercentileRatioMid35 &     FluxPercentileRatioMid50 &         FluxPercentileRatioMid65 &              \\\\\n",
      "    FluxPercentileRatioMid80 &  Freq1\\_harmonics\\_amplitude\\_0 &      Freq1\\_harmonics\\_amplitude\\_1 &              \\\\\n",
      " Freq1\\_harmonics\\_amplitude\\_2 &  Freq1\\_harmonics\\_amplitude\\_3 &      Freq1\\_harmonics\\_rel\\_phase\\_0 &              \\\\\n",
      " Freq1\\_harmonics\\_rel\\_phase\\_1 &  Freq1\\_harmonics\\_rel\\_phase\\_2 &      Freq1\\_harmonics\\_rel\\_phase\\_3 &              \\\\\n",
      "                 LinearTrend &                     MaxSlope &                             Mean &              \\\\\n",
      "                Meanvariance &                 MedianAbsDev &                        MedianBRP &              \\\\\n",
      "              PairSlopeTrend &             PercentAmplitude &  PercentDifferenceFluxPercentile &              \\\\\n",
      "                    PeriodLS &                   Period\\_fit &                           Psi\\_CS &              \\\\\n",
      "                     Psi\\_eta &                          Q31 &                              Rcs &              \\\\\n",
      "                        Skew &                SmallKurtosis &                              Std &              \\\\\n",
      "                    StetsonK &                       c89\\_c3 &                     c89\\_hk\\_color &              \\\\\n",
      "                c89\\_jh\\_color &                 c89\\_jk\\_color &                           c89\\_m2 &              \\\\\n",
      "                      c89\\_m4 &                          cnt &                           n09\\_c3 &              \\\\\n",
      "                n09\\_hk\\_color &                 n09\\_jh\\_color &                     n09\\_jk\\_color &              \\\\\n",
      "                      n09\\_m2 &                       n09\\_m4 &                             ppmb &              \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
>>>>>>> 355f3f69c644942bd910a5af461ce51c9b5f1bcd
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "no_features = [\"id\", \"vs_catalog\", \"vs_type\", \"ra_k\", \"dec_k\", ] \n",
    "X_columns = [c for c in s20k.columns if c not in no_features]\n",
    "print \"Features:\\n\\t\", \", \".join(X_columns)"
=======
    "feats = pd.DataFrame(splited).T\n",
    "feats\n",
    "print feats.to_latex(index=False)"
>>>>>>> 355f3f69c644942bd910a5af461ce51c9b5f1bcd
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juan/proyectos/paper_b278/local/lib/python2.7/site-packages/numpy/core/_methods.py:116: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n"
     ]
    }
   ],
>>>>>>> 355f3f69c644942bd910a5af461ce51c9b5f1bcd
   "source": [
    "scaler_20k = StandardScaler()\n",
    "norm_s20k = s20k.copy()\n",
    "norm_s20k[X_columns] = scaler_20k.fit_transform(s20k[X_columns])\n",
    "pickle.dump(scaler_20k, open(\"data/ogle3_only/scalers/scaler_20k.pkl\", \"wb\"))\n",
<<<<<<< HEAD
    "norm_s20k.to_pickle(\"data/ogle3_only/scaled/s20k.pkl\")"
=======
    "norm_s20k.to_pickle(\"data/ogle3_only/scaled/s20k.pkl.bz2\", compression=\"bz2\")"
>>>>>>> 355f3f69c644942bd910a5af461ce51c9b5f1bcd
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 16,
>>>>>>> 355f3f69c644942bd910a5af461ce51c9b5f1bcd
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_5k = StandardScaler()\n",
    "norm_s5k = s5k.copy()\n",
    "norm_s5k[X_columns] = scaler_5k.fit_transform(s5k[X_columns])\n",
    "pickle.dump(scaler_5k, open(\"data/ogle3_only/scalers/scaler_5k.pkl\", \"wb\"))\n",
<<<<<<< HEAD
    "norm_s5k.to_pickle(\"data/ogle3_only/scaled/s5k.pkl\")"
=======
    "norm_s5k.to_pickle(\"data/ogle3_only/scaled/s5k.pkl.bz2\", compression=\"bz2\")"
>>>>>>> 355f3f69c644942bd910a5af461ce51c9b5f1bcd
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 17,
>>>>>>> 355f3f69c644942bd910a5af461ce51c9b5f1bcd
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_2_5k = StandardScaler()\n",
    "norm_s2_5k = s2_5k.copy()\n",
    "norm_s2_5k[X_columns] = scaler_2_5k.fit_transform(s2_5k[X_columns])\n",
    "pickle.dump(scaler_2_5k, open(\"data/ogle3_only/scalers/scaler_2_5k.pkl\", \"wb\"))\n",
<<<<<<< HEAD
    "norm_s2_5k.to_pickle(\"data/ogle3_only/scaled/s2_5k.pkl\")"
=======
    "norm_s2_5k.to_pickle(\"data/ogle3_only/scaled/s2_5k.pkl.bz2\", compression=\"bz2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = {k: {\"Tile\": k} for k in \"b261 b262 b263 b264 b278\".split()}\n",
    "    \n",
    "for nombre, s in zip([\"Chica\", \"Mediana\", \"Grande\"] , [s2_5k,s5k,s20k]):\n",
    "    s = s.copy()\n",
    "    s[\"tile\"] = s[\"id\"].apply(lambda i: \"b\" + str(i)[1:4])\n",
    "    grouped = s.groupby(\"tile\")\n",
    "    data = {k: grouped.get_group(k).copy() for k in grouped.groups.keys()}\n",
    "    for tile, df in data.items():\n",
    "        row = rows[tile]\n",
    "        row.update({\n",
    "            nombre : len(df[df.vs_type.str.contains(\"\")]),\n",
    "            \"RR-Lyrae\": len(df[df.vs_type.str.startswith(\"RRLyr\")]),\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      " Tile &  Chica &  Mediana &  Grande &  RR-Lyrae \\\\\n",
      "\\midrule\n",
      " b261 &   2718 &     5212 &   20193 &       221 \\\\\n",
      " b262 &   2791 &     5288 &   20247 &       296 \\\\\n",
      " b263 &   2805 &     5302 &   20293 &       305 \\\\\n",
      " b264 &   2792 &     5292 &   20289 &       294 \\\\\n",
      " b278 &   2912 &     5406 &   20354 &       423 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print pd.DataFrame(\n",
    "    [v for v in rows.values()]\n",
    ")[\n",
    "    \"Tile Chica Mediana Grande RR-Lyrae\".split()\n",
    "].sort_values(\"Tile\").to_latex(index=False)"
>>>>>>> 355f3f69c644942bd910a5af461ce51c9b5f1bcd
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
<<<<<<< HEAD
   "version": "2.7.14"
=======
   "version": "2.7.12"
>>>>>>> 355f3f69c644942bd910a5af461ce51c9b5f1bcd
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
